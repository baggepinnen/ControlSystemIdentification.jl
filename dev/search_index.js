var documenterSearchIndex = {"docs":
[{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"In this example, we will estimate a model for a glass furnace. ","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"We will get the data from STADIUS's Identification Database","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"using DelimitedFiles, Plots\nusing ControlSystemIdentification, ControlSystemsBase\ngr(fmt=:png) # hide\n\nurl = \"https://ftp.esat.kuleuven.be/pub/SISTA/data/process_industry/glassfurnace.dat.gz\"\nzipfilename = \"/tmp/furnace.dat.gz\"\npath = Base.download(url, zipfilename)\nrun(`gunzip -f $path`)\ndata = readdlm(path[1:end-3])\nu = data[:, 2:4]'  \ny = data[:, 5:10]'\nd = iddata(y, u, 1)","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"The input consists of two heating inputs and one cooling input, while there are 6 outputs from temperature sensors in a cross section of the furnace.","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"Before we estimate any model, we inspect the data","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"plot(d, layout=9)","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"We split the data in two, and use the first part for estimation and the second for validation. This system requires zeroD=false to be able to capture a direct feedthrough to output 4, otherwise the fit for output 4 will always be rather poor.","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"dtrain = d[1:2end÷3]\ndval = d[2end÷3:end]\n\nmodel = subspaceid(dtrain, 7, zeroD=false)\nnothing # hide","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"We can have a look at the D matrix in the estimated model","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"model.D","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"indeed, the (4,3) element is rather large. ","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"We validate the model by prediction on the validation data:","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"predplot(model, dval, h=1, layout=6)\npredplot!(model, dval, h=10, ploty=false)","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"The figures above show the result of predicting h=1 10 steps into the future.","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"We can visualize the estimated model in the frequency domain as well. ","category":"page"},{"location":"examples/glass_furnace/","page":"Glass furnace","title":"Glass furnace","text":"w = exp10.(LinRange(-3, log10(pi/d.Ts), 200))\nsigmaplot(model.sys, w, lab=\"MOESP\")","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"A typical model for a temperature-controlled system is ","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"tau dot T = -T  + Bu + c","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"where T is the temperature, u the control signal and c a constant offset, e.g., related to the temperature surrounding the controlled system. The time constant tau captures the relation between stored energy and the resistance to heat flow and determines how fast the temperature is changing. This system can be written on transfer-function form like (omitting c)","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"dfracBtau s + 1U(s)","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"This is a simple first-order transfer function which can be estimated with, e.g., the functions arx or plr. To illustrate this, we create such a system and simulate some data from it.","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"using ControlSystemsBase, ControlSystemIdentification, Plots\ngr(fmt=:png) # hide\nw = 2pi .* exp10.(LinRange(-3, log10(0.5), 500))\nG0 = tf(1, [10, 1]) # The true system, 10ẋ = -x + u\nG = c2d(G0, 1)      # discretize with a sample time of 1s\nprintln(\"True system\")\ndisplay(G0)\n\nu = sign.(sin.((0:0.01:20) .^ 2))' # sample a control input for identification\ny, t, x = lsim(ss(G), u) # Simulate the true system to get test data\nyn = y .+ 0.2 .* randn.() # add measurement noise\ndata = iddata(yn, u, t[2] - t[1]) # create a data object\nplot(data)","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"We see that the data we're going to use for identification is a chirp input. Chirps are excellent for identification as they have a well defined and easily controllable interval of frequencies for identification. We start by inspecting the coherence plot to ensure that the data is suitable for identification of a linear system","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"coherenceplot(data, hz=true)","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"The coherence is high for all frequencies spanned by the chirp, after which it drops significantly. This implies that we can only ever trust the identified model to be accurate up to the highest frequency that was present in the chirp input.","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"Next we set the parameters for the estimation, the numerator and denominator have one parameter each, so we set n_a = n_b = 1 and estimate two models.","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"na, nb = 1, 1 # number of parameters in denominator and numerator\nGh = arx(data, na, nb, estimator = wtls_estimator(data.y, na, nb)) # estimate an arx model\nGh2, noise_model = plr(data, na, nb, 1) # try another identification method\n\nGh, Gh2","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"Least-squares estimation of ARX models from data with high measurement noise is known to lead to models with poor low-frequency fit, we therefore used the wtls_estimator(data.y, na, nb) which performs the estimation with total-least squares.","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"We can plot the results in several different ways:","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"# Plot results\nprintln(\"Estimated system in continuous time\")\ndisplay(d2c(Gh)) # Convert from discrete to continuous time","category":"page"},{"location":"examples/temp/","page":"Temperature control","title":"Temperature control","text":"bp = bodeplot(G, w, lab = \"G (true)\", hz = true, l = 5)\nbodeplot!(Gh, w, lab = \"arx\", hz = true)\nbodeplot!(Gh2, w, lab = \"plr\", hz = true, ticks = :default)\n\nsp = plot(step(G, 150), lab=\"G (true)\")\nplot!(step(Gh, 150), lab = \"arx\")\nplot!(step(Gh2, 150), lab = \"plr\", ticks = :default)\nhline!([1], primary = false, l = (:black, :dash))\n\nlp = plot(lsim(ss(G), u), lab=\"G (true)\")\nplot!(lsim(ss(Gh), u), lab = \"arx\")\nplot!(lsim(ss(Gh2), u), lab = \"plr\", ticks = :default)\nplot!(data.t, yn[:], lab = \"Estimation data\", alpha=0.3)\n\nplot(bp, sp, lp, layout = @layout([[a b]; c]))","category":"page"},{"location":"examples/delayest/#Delay-estimation","page":"Delay estimation","title":"Delay estimation","text":"","category":"section"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"A frequent property of control systems is the presence of delays, either due to processing time, network latency, or other physical phenomena. Delays that occur internally in the system will in the discrete-time setting add a potentially large number of states to the system, tau  T_s state variables are required to represent a delay of tau seconds in a discrete-time system with sampling time T_s. A common special case is that the delay occurs at either the input or the output of the system, e.g, due to communication delays. Estimating this delay ahead of the estimation of the model is often beneficial, since it reduces the number of parameters that need to be estimated. Below, we generate a dataset with a large input delay tau and have a look at how we can estimate tau.","category":"page"},{"location":"examples/delayest/#Estimating-the-delay","page":"Delay estimation","title":"Estimating the delay","text":"","category":"section"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"using DelimitedFiles, Plots\nusing ControlSystemIdentification, ControlSystemsBase\ngr(fmt=:png) # hide\n\nτ  = 2.0 # Delay in seconds\nTs = 0.1 # Sampling time\nP  = c2d(tf(1, [1, 0.5, 1])*delay(τ), Ts) # Dynamics is given by a simple second-order system with input delay\n\nu   = sin.(0.1 .* (0:Ts:30).^2) # An interesting input signal\nres = lsim(P, u')\nd   = iddata(res)\nplot(d)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"If we inspect the (discrete-time) system, we see that it indeed has a large-dimensional state:","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"P.nx","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"A simple, non-parametric way of figuring out whether or not there's a delay in the system is to look at the cross-correlation between the input and the output, we can do this using the crosscorplot function:","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"crosscorplot(d)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"The plot indicates that there is insignificant (below the dashed lines) correlation between the input and the output for lags smaller than 2 seconds, corresponding exactly to our delay tau. ","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"Another method to identify the delay would be to estimate the impulse response of the system:","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"impulseestplot(d, 60; λ=0.5, lab=\"Estimated\", title=\"Impulse response of delay system\")\nplot!(impulse(P, 6), lab=\"True\", framestyle=:zerolines)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"Estimation of impulse responses in the presence of such large delays is numerically challenging, and a regularization of λ=05 was required to achieve a reasonable result. If the delay is expected to be large and the dataset is small, it is thus recommended to use the cross-correlation method instead, since we cannot tune the regularization parameter λ in a practical setting when we don't know what impulse response to expect. However, for short delays and large datasets, the impulse-response method works rather well. Below, we show the estimated impulse response for a much larger dataset just to demonstrate:","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"u2 = sin.(0.01 .* (0:Ts:300).^2) .+ randn.() # An interesting and long input signal with some noise as well\nres2 = lsim(P, u2')\nd2 = iddata(res2)\n\nimpulseestplot(d2, 200; λ=0.0, lab=\"Estimated\", title=\"Impulse response with large dataset\")\nplot!(impulse(P, 20), lab=\"True\", framestyle=:zerolines)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"A third method, arguably less elegant, is to use a model-selection method to figure out the delay. Presumably, models estiamted with an order smaller than the delay will be rather poor, something that should be visible if we try models of many orders. Below, we use the function find_nanb that tries to identify the appropriate model order for an arx model.","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"find_nanb(d, 2:8, 10:30, xrotation=90, size=(800, 300), margin=5Plots.mm, xtickfont=6)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"The plot indicates that the Akaike information criterion (AIC) is minimized when nb reaches 22, which happens to be the number of delay samples tau  T_s + the number of numerator parameters for the system without delay:","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"c2d(tf(1, [1, 0.5, 1]), Ts)","category":"page"},{"location":"examples/delayest/#Handling-the-delay-when-estimating-a-model","page":"Delay estimation","title":"Handling the delay when estimating a model","text":"","category":"section"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"Once we know that there is a delay present, we need to somehow handle it while estimating a model. The naive way is to simply select a model with high-enough order and call it a day. However, this is prone to numerical problems and generally not recommended. Some methods have a dedicated inputdelay keyword that allows you to specify known input delays, after which the method handles it internally. For methods that do not have this option, one can always preprocess the data to remove the delay, we show how to do this next:","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"τ_samples = 20 # Number of samples delay\nd2 = iddata(d.y[:, τ_samples+1:end], d.u[:, 1:end-τ_samples], d.Ts)\ncrosscorplot(d2)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"The cross-correlation plot now indicates that the delay is gone. Please note, one sample delay is most of the time expected, indeed, it's unrealistic for the output of a physical system to respond at the same time as something happens at the input. Once we have estimated a model with the dataset with the delay removed, we must add the delay back into the estimated model, e.g.,","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"P̂ = subspaceid(d2, focus=:simulation) # Estimate a model without delay\ntf(d2c(P̂)) # Does it match the original continuous-time system without delay?","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"The estimated model above should be very close to the system tf(1, [1, 0.5, 1]) (some small higher-order terms in the numerator are expected). To add the delay to this model, we do","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"P̂τ = P̂*delay(τ, Ts) # Note that this is different from delay(τ, Ts)*P̂ which adds output delay instead of input delay\nbodeplot([P, P̂τ], lab=[\"True system\" \"\" \"Estimated system\" \"\"])","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"The estimated model should now match the true system very well, including the large drop in phase for higher frequencies due to the delay.","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"warning: Internal delays\nIf the system contains internal delays, it might appear in a cross-correlation plot as if the system has an input-output delay, but in this case shifting the data like we did above may be ill-advised. With internal delays, use the number of estimated delay samples as a lower bound on the model order instead. An example of an internal delay is when a control loop is closed around a delayed channel, illustrated below.","category":"page"},{"location":"examples/delayest/#Internal-delays","page":"Delay estimation","title":"Internal delays","text":"","category":"section"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"In discrete time, a one-sample delay on either the input or the output appear as a pole in the origin. However, when the delay is internal to the system, it's not as easy to detect. Below, we close the loop around the system P from above using a PI controller C, and construct a new dataset where the input is the reference to the PI controller rather than the input to the plant. ","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"C = pid(0.1, 0.5; Ts)\nL = P*C\nG = feedback(L)\nplot(nyquistplot(L), plot(step(G, 50)))","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"ref = sign.(sin.(0.02 .* (0:Ts:50).^2)) # An interesting reference signal\nres = lsim(G, ref')\ndG = iddata(res)\nplot(plot(dG), crosscorplot(dG))","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"We see that the cross-correlation plot still indicates that it takes over 2 seconds for the output to be affected by the input, but if we look at the model-selection plot, we must include orders up to above 23 to get a good fit:","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"find_nanb(dG, 3:30, 5:30, xrotation=90, size=(800, 300), margin=5Plots.mm, xtickfont=6)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"We can also inspect the pole-zero maps of the open-loop and closed-loop systems","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"plot(\n    pzmap(P, title=\"Open-loop system\"),\n    pzmap(G, title=\"Closed-loop system\"),\n    plot_title=\"Pole-zero maps\",\n    layout=(1, 2),\n    ratio=:equal,\n    size=(800, 400),\n    xlims=(-1.1, 1.1),\n    ylims=(-1.1, 1.1),\n)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"the presence of the feedback has moved all the delay poles away from the origin (there are multiple poles on top of each other in the left plot).","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"In this case, we must thus estimate a model of fairly high order (23) in order to accurately capture the dynamics of the system. If we do this, we can see that the estimated model matches the true system very well (since we didn't add any disturbance):","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"model = subspaceid(dG, G.nx)\nsimplot(model, dG, zeros(model.nx))","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"In a practical scenario, estimating a model of such high order may be difficult. It might then be worthwhile trying to estimate the lower-order open-loop system P directly, taking care to properly handle the delay, which then appears on the input rather than internally.","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"If we use one of the methods that support the inputdelay keyword, we can see whether or not we can approximate the closed-loop system with a model that has an input delay only:","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"model2 = arx(dG, 4, 4, inputdelay=τ_samples)\nplot(\n    simplot(model2, dG),\n    pzmap(\n        model2,\n        ratio=:equal,\n        xlims=(-1.1, 1.1),\n        ylims=(-1.1, 1.1),\n        title=\"Estimated ARX model with input delay\",\n    )\n)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"We see that with a model of order 3 (4 free parameters in the denominator) together with a specified input delay of 20 samples, we indeed get a good approximation of the closed-loop system.","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"If we compare the Bode plots of the true closed-loop system with the two identified models, they match very well.","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"bodeplot([G, model, model2])","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"It may thus be possible to approximate a system with internal delays using a model that has an input delay only.","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"For completeness, we construct an example where this is not quite possible. The system in the example below can be thought of as an echo chamber, where the input passes through a resonant channel before it reaches the output, and 45% of the output energy is fed back at the input through the same channel (the echo)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"ref = sign.(sin.(0.02 .* (0:Ts:150).^2)) # An interesting reference signal\nPc = feedback(tf(1, [1, 1, 1]), tf(0.6, [1, 1, 1])*delay(τ)) # Feed 60% of the output back at the input with a delay of 2 seconds (like an echo)\nPd = c2d(Pc, Ts)\nres = lsim(Pd, ref')\ndecho = iddata(res)\nplot(bodeplot(Pd), pzmap(Pd), plot(decho))","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"The model-selection plot below indicates that we need to reach model orders of 24 to get a good fit","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"find_nanb(decho, 3:30, 5:30, xrotation=90, size=(800, 300), margin=5Plots.mm, xtickfont=6)","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"trying to estimate a 4:th order model with input delay of 20 samples does not work at all this time, but fitting a 24:th order model does","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"model3 = arx(decho, 5, 5, inputdelay=τ_samples)\nmodel4 = subspaceid(decho, 24)\nfigsim = simplot(model3, decho, zeros(ss(model3).nx), sysname=\"ARX\")\nsimplot!(model4, decho, zeros(model4.nx), ploty=false, plotu=false, sysname=\"Subspace\")","category":"page"},{"location":"examples/delayest/","page":"Delay estimation","title":"Delay estimation","text":"Keep in mind that we do not add any disturbance in our simulations here, and estimating 24:th order models is likely going to be a challenging task in practice.","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"In this example, we will estimate a model for a flexible robot arm. ","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"We will get the data from STADIUS's Identification Database","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"using DelimitedFiles, Plots\nusing ControlSystemIdentification, ControlSystemsBase\ngr(fmt=:png) # hide\n\nurl = \"https://ftp.esat.kuleuven.be/pub/SISTA/data/mechanical/robot_arm.dat.gz\"\nzipfilename = \"/tmp/flex.dat.gz\"\npath = Base.download(url, zipfilename)\nrun(`gunzip -f $path`)\ndata = readdlm(path[1:end-3])\nu = data[:, 1]' # torque\ny = data[:, 2]' # acceleration\nd = iddata(y, u, 0.01) # sample time not specified for data, 0.01 is a guess","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"The input consists of the motor torque and the output is the acceleration of the arm. ","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"Before we estimate any model, we inspect the data and the coherence function","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"xt = [2,5,10,20,50]\nplot(\n    plot(d),\n    coherenceplot(d, xticks=(xt,xt), hz=true),\n)","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"The coherence is low for high frequencies as well as frequencies between 2 and 6 Hz. We should thus be careful with relying on the estimated model too much in these frequency ranges. The reason for the low coherence may be either a poor signal-to-noise ratio, or the presence of nonlinearities. For systems with anti-resonances, like this one, the SNR is often poor at the notch frequencies (indeed, a notch frequency is defined as a frequency where there will be very little signal). We can investigate the spectra of the input and output using welchplot (see also specplot)","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"welchplot(d, yticks=(xt,xt))","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"Not surprisingly, we see that the input has very little power above 20Hz, this is the reason for the low coherence above 20Hz. Limiting the bandwidth of the excitation signal is usually a good thing, mechanical structures often exhibit higher-order resonances and nonlinear behavior at high frequencies, which we see eveidence of in the output spectrum at around 34Hz.","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"We also split the data in half, and use the first half for estimation and the second for validation. We'll use a subspace-based identification algorithm for estimation","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"dtrain = d[1:end÷2]\ndval = d[end÷2:end]\n\n# A model of order 4 is reasonable, a double-mass model. We estimate two models, one using subspace-based identification and one using the prediction-error method\nmodel_ss = subspaceid(dtrain, 4, focus=:prediction)\nmodel_pem, _ = newpem(dtrain, 4; sys0 = model_ss, focus=:prediction)\n\npredplot(model_ss, dval, h=1)\npredplot!(model_ss, dval, h=5, ploty=false)\nsimplot!(model_ss, dval, ploty=false)","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"The figures above show the result of predicting h=1 10 infty steps into the future.","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"We can visualize the estimated models in the frequency domain as well. We show both the model estimated using PEM and a nonparametric estimate using a Fourier-based method (tfest), this method estimates a noise model as well.","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"w = exp10.(LinRange(-1, log10(pi/d.Ts), 200))\nbodeplot(model_pem.sys, w, lab=\"PEM\", plotphase=false, hz=true)\nbodeplot!(model_ss.sys, w, lab=\"Subspace\", plotphase=false, hz=true)\nplot!(tfest(d), legend=:bottomleft, hz=true, xticks=(xt,xt))","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"It looks like the model fails to capture the notches accurately. Estimating zeros is known to be hard, both in practice and in theory. In the estimated disturbance (labeled Noise), we see a peak at around 34Hz. This is likely an overtone due to nonlinearities.","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"We can also investigate how well the models predict for various prediction horizons, and compare that to how well the model does in open loop (simulation)","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"using Statistics\nhs = [1:40; 45:5:80]\nperrs_pem = map(hs) do h\n    yh = predict(model_pem, d; h)\n    ControlSystemIdentification.rms(d.y - yh) |> mean\nend\nperrs_ss = map(hs) do h\n    yh = predict(model_ss, d; h)\n    ControlSystemIdentification.rms(d.y - yh) |> mean\nend\nserr_pem = ControlSystemIdentification.rms(d.y - simulate(model_pem, d)) |> mean\nserr_ss = ControlSystemIdentification.rms(d.y - simulate(model_ss, d)) |> mean\n\nplot(hs, perrs_pem, lab=\"Prediction errors PEM\", xlabel=\"Prediction Horizon\", ylabel=\"RMS error\")\nplot!(hs, perrs_ss, lab=\"Prediction errors Subspace\")\nhline!([serr_pem], lab=\"Simulation error PEM\", l=:dash, c=1, ylims=(0, Inf))\nhline!([serr_ss], lab=\"Simulation error Subspace\", l=:dash, c=2, legend=:bottomright, ylims=(0, Inf))","category":"page"},{"location":"examples/flexible_robot/","page":"Flexible robot arm","title":"Flexible robot arm","text":"We see that the prediction-error model does slightly better at prediction few-step predictions (indeed, this is what PEM optimizes), while the model identified using subspaceid does better in open loop. The simulation performance can be improved upon further by asking for focus=:prediction when the models are estimated.","category":"page"},{"location":"examples/varx/#Vector-Autoregressive-with-External-inputs-(VARX)","page":"VARX model","title":"Vector Autoregressive with External inputs (VARX)","text":"","category":"section"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"In some fields, the use of VARX is widespread. VARX models are special cases of general linear models on the form","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"beginaligned\nx^+ = Ax + Bu + Ke\ny = Cx + Du + e\nendaligned","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"which we show here by simulating the VARX model","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"y_t = A_1 y_t-1 + A_2 y_t-2 + B_1 u_t-1","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"and estimating a regular statespace model. ","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"using ControlSystemIdentification, Plots\n\nA1 = 0.3randn(2,2)\nA2 = 0.3randn(2,2)\nB1 = randn(2,2)\n\nN = 300\nY = [randn(2), randn(2)]\nu = randn(2, N)\n\nfor i = 3:N\n    yi = A1*Y[i-1] + A2*Y[i-2] + B1*u[:,i-1]\n    push!(Y, yi)\nend\n\ny = hcat(Y...)\n\nd = iddata(y, u, 1)","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"We now estimate two models, one using subspace-based identification (subspaceid) and one using the prediction-error method (newpem). The VARX model we estimated had a state of order 4, two lags of y, each of which is a vector of length 2, we thus estimate models of order 4 below.","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"model1 = subspaceid(d, 4, zeroD=true)\nmodel2, x0 = newpem(d, 4)\n\nplot(\n    simplot(d, model1, title=\"Simulation subspaceid\", layout=2),\n    simplot(d, model2, x0, title=\"Simulation PEM\", layout=2),\n    titlefontsize=10,\n)","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"The simulation indicates that the fit is close to 100%, i.e., the general linear model fit the VARX model perfectly, it does not however have exactly the same structure as the original VARX model. ","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"The estimated models on statespace form can be converted to MIMO transfer functions (polynomial models) by calling tf:","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"using ControlSystemsBase: tf\ntf(model2.sys)","category":"page"},{"location":"examples/varx/#Summary","page":"VARX model","title":"Summary","text":"","category":"section"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"The statespace model","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"beginaligned\nx^+ = Ax + Bu + Ke\ny = Cx + Du + e\nendaligned","category":"page"},{"location":"examples/varx/","page":"VARX model","title":"VARX model","text":"is very general and subsumes a lot of other, special-structure models, like the VARX model.","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"In this example, we will estimate a model for a laboratory setup acting like a hair dryer. Air is fanned through a tube and heated at the inlet. The air temperature is measured by a thermocouple at the output. The input is the voltage over the heating device (a mesh of resistor wires).","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"The example comes from STADIUS's Identification Database.","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"An extension to this example where an MPC controller is designed for the estimated system can be found here, as well as in video form here.","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"Ljung L.  System identification - Theory for the User. Prentice Hall, Englewood Cliffs, NJ, 1987. ","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"using DelimitedFiles, Plots\nusing ControlSystemIdentification, ControlSystemsBase\n\nurl = \"https://ftp.esat.kuleuven.be/pub/SISTA/data/mechanical/dryer.dat.gz\"\nzipfilename = \"/tmp/dryer.dat.gz\"\npath = Base.download(url, zipfilename)\nrun(`gunzip -f $path`)\ndata = readdlm(path[1:end-3])\nu = data[:, 1]' # voltage\ny = data[:, 2]' # air temp\nd = iddata(y, u, 0.08) # sample time not specified for data, 0.08 is a guess","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"The input consists of the voltage to the heating element and the output is the air temperature","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"Before we estimate any model, we inspect the data and the coherence function","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"plot(\n    plot(d),\n    coherenceplot(d),\n)","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"The coherence looks good up until about 10 rad/s, above this frequency we can not trust the model. We notice that the data is not zero centered, and thus remove the mean before continuing (remember to correctly handle the operating point when controlling a process). If we look at an estimated impulse response","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"d = detrend(d)\nimpulseestplot(d, 40, σ=3)","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"we see that there is a three step input delay. ","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"Before we estimate models, we split the data in a estimation set and a validation set. We then estimate two different models, one using hte prediction-error method (newpem) and one using standard least-squares (arx). When we estimate the ARX model, we tell the estimator that we have a known input delay of 3 samples. We then validate the estimated models by using them for prediction and simulation on the validation data.","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"dtrain = d[1:end÷2]\ndval = d[end÷2:end]\n## A model of order 3 is reasonable.\nmodel_pem,_ = newpem(dtrain, 3)\nmodel_arx = arx(dtrain, 2, 2, inputdelay=3)\n\npredplot(model_pem, dval, sysname=\"PEM\")\npredplot!(model_arx, dval, ploty=false, sysname=\"ARX\")\nsimplot!(model_pem, dval, ploty=false, sysname=\"PEM\")\nsimplot!(model_arx, dval, ploty=false, sysname=\"ARX\")","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"The models are roughly comparable, where the PEM model is slightly better at prediction while the ARX model is slightly better at simulation. Note, newpem takes a keyword argument focus that can be set to focus = :simulation in order to improve simulation performance.","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"To finalize, we compare the models in the frequency domain to a nonparametric estimate of the transfer function made with Fourier-based methods (tfest):","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"w = exp10.(LinRange(-1, log10(pi/d.Ts), 200))\nbodeplot(model_pem.sys, w, lab=\"PEM\", plotphase=false)\nbodeplot!(model_arx, w, lab=\"ARX\", plotphase=false)\nplot!(tfest(d))","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"The two parametric models are quite similar and agree well with the nonparametric estimate. We also see that the nonparametric estimate becomes rather noisy above 10 rad/s, something we could predict based on the coherence function.","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"We can compare the impulse responses of the estimated model to the impulse response that was estimated directly from data above:","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"impulseestplot(d, 40, σ=3, lab=\"Data\", seriestype=:steppost)\nplot!(impulse(model_pem, 3), lab=\"PEM\")\nplot!(impulse(model_arx, 3), lab=\"ARX\")","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"The ARX model has an impulse response that is exactly zero for the first three samples since we indicated inputdelay=3 when estimating this model. The PEM model did not know this, but figured it out from the data nevertheless.","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"As a last step of validation, we perform residual analysis. If a model has extracted all available useful information from the data, the residuals should form a white-noise sequence, and there should be no correlation between the input and the residuals. To this end, we have the function residualplot:","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"residualplot(model_pem, dval, lab=\"PEM\")\nresidualplot!(model_arx, dval, lab=\"ARX\")","category":"page"},{"location":"examples/hair_dryer/","page":"Hair dryer","title":"Hair dryer","text":"As we can see, there is some slight correlation left in the residuals, the dashed black lines show 95% significance levels. This small amount of correlation is usually nothing to worry about if the model fit is high, i.e., the residuals are small, and we'll thus consider ourselves done at this point.","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"In this example, we will estimate a model for a four-stage evaporator to reduce the water content of a product, for example milk. The 3 inputs are feed flow, vapor flow to the first evaporator stage and cooling water flow. The three outputs are the dry matter content, the flow and the temperature of the outcoming product.","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"The example comes from STADIUS's Identification Database ","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"Zhu Y., Van Overschee P., De Moor B., Ljung L., Comparison of three classes of identification methods. Proc. of SYSID '94, ","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"using DelimitedFiles, Plots\nusing ControlSystemIdentification, ControlSystemsBase\ngr(fmt=:png) # hide\n\nurl = \"https://ftp.esat.kuleuven.be/pub/SISTA/data/process_industry/evaporator.dat.gz\"\nzipfilename = \"/tmp/evaporator.dat.gz\"\npath = Base.download(url, zipfilename)\nrun(`gunzip -f $path`)\ndata = readdlm(path[1:end-3])\n# Inputs:\n# \tu1: feed flow to the first evaporator stage\n# \tu2: vapor flow to the first evaporator stage\n# \tu3: cooling water flow\n# Outputs:\n# \ty1: dry matter content\n# \ty2: flow of the outcoming product\n# \ty3: temperature of the outcoming product\nu = data[:, 1:3]'  \ny = data[:, 4:6]'\nd = iddata(y, u, 1) ","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"The input consists of two heating inputs and one cooling input, while there are 6 outputs from temperature sensors in a cross section of the furnace.","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"Before we estimate any model, we inspect the data","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"plot(d, layout=6)","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"We split the data in two, and use the first part for estimation and the second for validation. A model of order around 8 is reasonable (the paper uses 6-13). This system requires the option zeroD=false to be able to capture a direct feedthrough, otherwise the fit will always be rather poor.","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"dtrain = d[1:3300] # first experiment ends after 3300 seconds\ndval = d[3301:end]\n\nmodel,_ = newpem(dtrain, 8, zeroD=false)\nnothing # hide","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"predplot(model, dval, h=1, layout=d.ny)\npredplot!(model, dval, h=5, ploty=false)","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"The figures above show the result of predicting h=1 5 steps into the future.","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"We can visualize the estimated model in the frequency domain as well. ","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"w = exp10.(LinRange(-2, log10(pi/d.Ts), 200))\nsigmaplot(model.sys, w, lab=\"PEM\", plotphase=false)","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"Let's compare prediction performance to the paper","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"ys = predict(model, dval, h=5)\nControlSystemIdentification.mse(dval.y-ys)","category":"page"},{"location":"examples/evaporator/","page":"Evaporator","title":"Evaporator","text":"The authors got the following errors: [0.24, 0.39, 0.14]","category":"page"},{"location":"impulse/#Impulse-response-estimation","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"","category":"section"},{"location":"impulse/","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"The functions impulseest(data, order; λ=0, estimator=ls) and impulseestplot perform impulse-response estimation by fitting a high-order FIR model. The function okid estimates Markov parameters and is applicable to MIMO systems.","category":"page"},{"location":"impulse/","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"SISO example","category":"page"},{"location":"impulse/","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"T = 200\nh = 1\nt = 0:h:T-h\nsys = c2d(tf(1,[1,2*0.1,0.1]),h)\n\nu  = randn(1, length(t))\nres = lsim(sys, u, t)\nd  = iddata(res)\n\nimpulseestplot(d,50, lab=\"Estimate\", seriestype=:steppost)\nplot!(impulse(sys,50), lab=\"True system\", l=:dash)","category":"page"},{"location":"impulse/","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"(Image: window)","category":"page"},{"location":"impulse/","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"MIMO example","category":"page"},{"location":"impulse/","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"using ControlSystemIdentification, ControlSystemsBase, Plots\nT = 200\nh = 1\nt = 0:h:T-h\nsys = ssrand(2,2,4, proper=true, Ts=h)\n\nu  = randn(sys.nu, length(t))\nres = lsim(sys, u, t)\nd  = iddata(res)\n\nH = okid(d, sys.nx)\nplot(impulse(sys,50), lab=\"True system\", layout=sys.ny+sys.nu, sp=(1:4)')\nplot!(reshape(H, sys.nu+sys.ny, :)', lab=\"OKID Estiamte\", seriestype=:steppre, l=:dash)","category":"page"},{"location":"impulse/","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"See the example notebooks for more details.","category":"page"},{"location":"impulse/#Estimate-model-from-impulse-response-data","page":"Impulse-response estimation","title":"Estimate model from impulse-response data","text":"","category":"section"},{"location":"impulse/","page":"Impulse-response estimation","title":"Impulse-response estimation","text":"The era (\"Eigenvalue realization algorithm\") and okid (\"Observer Kalman identification\") algorithms are often used together, where the latter estimates the Markov parameters (impulse response) and the former takes those and estimates a statespace model. If you have the Markov parameters already, you can call era directly to estimate a model from an impulse response.","category":"page"},{"location":"freq/#Transfer-function-estimation-using-spectral-techniques","page":"Frequency-domain estimation","title":"Transfer-function estimation using spectral techniques","text":"","category":"section"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"Frequency-domain estimation refers to estimation of linear systems using frequency-domain data. We distinguish between nonparametric and parametric models, where parametric models have a fixed number of parameters (such as transfer functions with polynomials or statespace models), whereas nonparametric models are typically given as vectors of frequency-response values over a grid of frequencies, i.e., the number of parameters is not fixed and grows with the number of data points.","category":"page"},{"location":"freq/#Nonparametric-estimation","page":"Frequency-domain estimation","title":"Nonparametric estimation","text":"","category":"section"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"Non-parametric estimation refers to the estimation of a model without a fixed number of parameters. Instead, the number of estimated parameters typically grows with the size of the data. This form of estimation can be useful to gain an initial understanding of the system, before selecting model orders etc. for a more standard parametric model. We provide non-parametric estimation of transfer functions through spectral estimation. To illustrate, we once again simulate some data:","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"using ControlSystemIdentification, ControlSystemsBase, Plots\ngr(fmt=:png) # hide\nT          = 100000\nh          = 1\nsim(sys,u) = lsim(sys, u, 1:T)[1][:]\nσy         = 0.5\nsys        = tf(1,[1,2*0.1,0.1])\nωn         = sqrt(0.3)\nsysn       = tf(σy*ωn,[1,2*0.1*ωn,ωn^2])\n\nu  = randn(1, T)\ny  = sim(sys, u)\nyn = y + sim(sysn, randn(size(u))) # Add noise filtered through sysn\nd  = iddata(y,u,h)\ndn = iddata(yn,u,h)","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"We can now estimate the coherence function to get a feel for whether or nor our data seems to be generated by a linear system:","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"k = coherence(d)  # Should be close to 1 if the system is linear and noise free\nk = coherence(dn) # Slightly lower values are obtained if the system is subject to measurement noise","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"We can also estimate a transfer function using spectral techniques, the main entry point to this is the function tfest, which returns a transfer-function estimate and an estimate of the power-spectral density of the noise (note, the unit of the PSD is squared compared to a transfer function, hence the √N when plotting it in the code below):","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"G,N = tfest(dn)\nbodeplot([sys,sysn], exp10.(range(-3, stop=log10(pi), length=200)), layout=(1,3), plotphase=false, subplot=[1,2,2], ylims=(0.1,300), linecolor=:blue)\n\ncoherenceplot!(dn, subplot=3)\nplot!(G, subplot=1, lab=\"G Est\", alpha=0.3, title=\"Process model\")\nplot!(√N, subplot=2, lab=\"N Est\", alpha=0.3, title=\"Noise model\")","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"(Image: window)","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"The left figure displays the Bode magnitude of the true system, together with the estimate (noisy), and the middle figure illustrates the estimated noise model. The right figure displays the coherence function (coherenceplot), which is close to 1 everywhere except for at the resonance peak of the noise log10(sqrt(0.3)) = -0.26.","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"See the example notebooks for more details.","category":"page"},{"location":"freq/#Parametric-estimation","page":"Frequency-domain estimation","title":"Parametric estimation","text":"","category":"section"},{"location":"freq/#Transfer-functions","page":"Frequency-domain estimation","title":"Transfer functions","text":"","category":"section"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"To estimate a parametric, rational transfer function from frequency-domain data, call tfest with an FRD object and an initial guess for the system model. This initial guess determines the number of coefficients in the numerator and denominator of the estimated model.","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"G0 = tf(1.0, [1,1,1]) # Initial guess\nG = tfest(d::FRD, G0)","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"Internally, Optim is using a gradient-based optimizer to find the optimal fit of the bode curve of the system. The default optimizer BFGS can be changed, see the docstring ?tfest.","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"For a comparison between estimation in the time and frequency domains, see this notebook.","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"If the above problem is hard to solve, you may parametrize the model using, e.g., a Laguerre basis expansion, example:","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"basis = laguerre_oo(1, 50) # Use 50 basis functions, the final model order may be reduced with baltrunc\nGest,p = tfest(d::FRD, basis)","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"note: Note\nMost methods for frequency-domain estimation of transfer functions handle SISO or SIMO systems only. For estimation of MIMO systems, consider using state-space based methods and convert the result to a transfer function using tf after estimation if required. ","category":"page"},{"location":"freq/#Statespace","page":"Frequency-domain estimation","title":"Statespace","text":"","category":"section"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"The function subspaceid handles frequency-domain data (as well as time-domain data). If an InputOutputFreqData is passed (may be created with function iddata), a frequency-domain method is automatically used. Further, a frequency-response object, FRD, may also be passed, in which case it is transformed to an InputOutputFreqData automatically. If the frequency-response data stems from a frequency-response analysis, you may need to perform a bilinear transform on the frequency axis of the data object to convert the continuous-time frequency axis to discrete time, example:","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"Ts    = 0.01 # Sample time\nfrd_d = c2d(frd_c::FRD, Ts) # Perform a bilinear transformation to discrete-time frequency vector\nPh, _ = subspaceid(frd_d, Ts, nx)","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"This can be done automatically by passing bilinear_transform = true to subspaceid.","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"The following example generates simulated frequency-response data frd from a random system, this data could in practice have come from a frequency-response analysis. We then use the data to fit a model using subspace-based identification in the frequency domain using subspaceid.","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"using ControlSystemIdentification, ControlSystemsBase, Plots\nny,nu,nx = 2,3,5                        # number of outputs, inputs and states\nTs = 1                                  # Sample time\nG = ssrand(ny,nu,nx; Ts, proper=true)   # Generate a random system\n\nN = 200             # Number of frequency points\nw = freqvec(Ts, N)\nfrd = FRD(w, G)     # Build a frequency-response data object (this should in practice come from an experiment) \n\nGh, x0 = subspaceid(frd, G.Ts, nx; zeroD=true) # Fit frequency response\nsigmaplot([G, Gh], w[2:end], lab=[\"True system\" \"Estimated model\"])","category":"page"},{"location":"freq/#Model-based-spectral-estimation","page":"Frequency-domain estimation","title":"Model-based spectral estimation","text":"","category":"section"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"The model estimation procedures can be used to estimate spectrograms. This package extends some methods from DSP.jl to accept a estimation function as the second argument. To create a suitable such function, we provide the function model_spectrum. Usage is illustrated below.","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"using ControlSystemIdentification, DSP\nT  = 1000\nfs = 1\ns = sin.((1:1/fs:T) .* 2pi/10) + 0.5randn(T)\nS1 = spectrogram(s,window=hanning, fs=fs)            # Standard spectrogram\nestimator = model_spectrum(ar,1/fs,6)\nS2 = spectrogram(s,estimator,window=rect, fs=fs)     # Model-based spectrogram\nplot(plot(S1,title=\"Standard Spectrogram\"),plot(S2,title=\"AR Spectrogram\")) # Requires the package LPVSpectral.jl","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"(Image: window)","category":"page"},{"location":"freq/","page":"Frequency-domain estimation","title":"Frequency-domain estimation","text":"ControlSystemIdentification.tfest\nControlSystemIdentification.coherence\nControlSystemIdentification.laguerre_oo\nControlSystemIdentification.model_spectrum\nControlSystemIdentification.welchplot\nControlSystemIdentification.specplot\nControlSystemIdentification.coherenceplot\nControlSystemIdentification.autocorplot\nControlSystemIdentification.crosscorplot","category":"page"},{"location":"freq/#ControlSystemIdentification.tfest","page":"Frequency-domain estimation","title":"ControlSystemIdentification.tfest","text":"H, N = tfest(data, σ = 0.05)\n\nEstimate a transfer function model using the Correlogram approach. Both H and N are of type FRD (frequency-response data).\n\nσ determines the width of the Gaussian window applied to the estimated correlation functions before FFT. A larger σ implies less smoothing.\nH = Syu/Suu             Process transfer function\nN = Sy - |Syu|²/Suu     Noise PSD\n\n\n\n\n\ntfest(\n    data::FRD,\n    p0,\n    link = log ∘ abs;\n    freq_weight = sqrt(data.w[1]*data.w[end]),\n    refine = true,\n    opt = BFGS(),\n    opts = Optim.Options(\n        store_trace       = true,\n        show_trace        = true,\n        show_every        = 1,\n        iterations        = 100,\n        allow_f_increases = false,\n        time_limit        = 100,\n        x_tol             = 0,\n        f_tol             = 0,\n        g_tol             = 1e-8,\n        f_calls_limit     = 0,\n        g_calls_limit     = 0,\n    ),\n)\n\nFit a parametric transfer function to frequency-domain data.\n\nThe initial pahse of the optimization solves\n\noperatornameminimize_BA Bl - A\n\nand the second stage (if refine=true) solves \n\noperatornameminimize_BA textlinkleft(dfracBAright) - textlinkleft(lright)\n\n(abs2(link(B/A) - link(l)))\n\nArguments:\n\ndata: An FRD onbject with frequency domain data.\np0: Initial parameter guess. Can be a NamedTuple or ComponentVector with fields b,a specifying numerator and denominator as they appear in the call to tf, i.e., (b = [1.0], a = [1.0,1.0,1.0]). Can also be an instace of TransferFunction.\nlink: By default, phase information is discarded in the fitting. To include phase, change to link = log.\nfreq_weight: Apply weighting with the inverse frequency. The value determines the cutoff frequency before which the weight is constant, after which the weight decreases linearly. Defaults to the geometric mean of the smallest and largest frequency.\nrefine: Indicate whether or not a second optimization stage is performed to refine the results of the first.\nopt: The Optim optimizer to use.\nopts: Optim.Options controlling the solver options.\n\nSee also minimum_phase to transform a possibly non-minimum phase system to minimum phase.\n\n\n\n\n\ntfest(data::FRD, basis::AbstractStateSpace; \n    freq_weight = 1 ./ (data.w .+ data.w[2]),\n    opt = BFGS(),\n    metric::M = abs2,\n    opts = Optim.Options(\n        store_trace       = true,\n        show_trace        = true,\n        show_every        = 50,\n        iterations        = 1000000,\n        allow_f_increases = false,\n        time_limit        = 100,\n        x_tol             = 1e-5,\n        f_tol             = 0,\n        g_tol             = 1e-8,\n        f_calls_limit     = 0,\n        g_calls_limit     = 0,\n)\n\nFit a parametric transfer function to frequency-domain data using a pre-specified basis.\n\nArguments:\n\ndata: An FRD onbject with frequency domain data.\n\nfunction kautz(a::AbstractVector)\n\nbasis: A basis for the estimation. See, e.g., laguerre, laguerre_oo, kautz\nfreq_weight: A vector of weights per frequency. The default is approximately 1/f. \nopt: The Optim optimizer to use.\nopts: Optim.Options controlling the solver options.\n\n\n\n\n\n","category":"function"},{"location":"freq/#ControlSystemIdentification.coherence","page":"Frequency-domain estimation","title":"ControlSystemIdentification.coherence","text":"κ = coherence(d; n = length(d)÷10, noverlap = n÷2, window=hamming)\n\nCalculates the magnitude-squared coherence Function. κ close to 1 indicates a good explainability of energy in the output signal by energy in the input signal. κ << 1 indicates that either the system is nonlinear, or a strong noise contributes to the output energy.\n\nκ: Coherence function (not squared) in the form of an FRD.\n\nSee also coherenceplot\n\n\n\n\n\n","category":"function"},{"location":"freq/#ControlSystemIdentification.laguerre_oo","page":"Frequency-domain estimation","title":"ControlSystemIdentification.laguerre_oo","text":"laguerre_oo(a::Number, Nq)\n\nConstruct an output orthogonalized Laguerre basis of length Nq with poles at -a.\n\n\n\n\n\n","category":"function"},{"location":"freq/#ControlSystemIdentification.model_spectrum","page":"Frequency-domain estimation","title":"ControlSystemIdentification.model_spectrum","text":"model_spectrum(f, h, args...; kwargs...)\n\nArguments:\n\nf: the model-estimation function, e.g., ar,arma\nh: The sample time\nargs: arguments to f\nkwargs: keyword arguments to f\n\nExample:\n\nusing ControlSystemIdentification, DSP\nT = 1000\ns = sin.((1:T) .* 2pi/10)\nS1 = spectrogram(s,window=hanning)\nestimator = model_spectrum(ar,1,2)\nS2 = spectrogram(s,estimator,window=rect)\nplot(plot(S1),plot(S2)) # Requires the package LPVSpectral.jl\n\n\n\n\n\n","category":"function"},{"location":"examples/unstable_systems/#Identification-of-unstable-systems","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"","category":"section"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"Unstable systems present several interesting challenges for system identification.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"The most obvious problem is that it becomes hard to collect experimental data for an unstable system. Imagine trying to estimate a model for a quadrotor, without an already working stabilizing controller, the quadrotor will fall to the ground and crash immediately.\nWith a stabilizing controller, the data collected from the system is comprised of closed-loop data, with all the implications that this has on the identification process. See the tutorial Closed-loop identification for more details on this.\nThe final problem is more subtle, it's even impossible to properly simulate the system in open loop! To see this, consider the example below.","category":"page"},{"location":"examples/unstable_systems/#Simulating-an-unstable-system","page":"Identification of unstable systems","title":"Simulating an unstable system","text":"","category":"section"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"In this little example, we form the very simple, unstable linear system","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"dotx = x + u + d","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"where u is the control input and d = sin(t) is a disturbance. We first simulate this system with a stabilizing feedback u = -Lx and save the data. We then simulate the same system again with the saved data as input, but a slightly different initial condition. Intuitively, the two simulations should look the same, it's the same system and the same input data, the only difference is the tiny change to the initial condition. ","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"using ControlSystemsBase, Plots, LinearAlgebra\nsys = tf(1.0, [1, -1]) |> ss # One-state unstable linear system\nsys = c2d(sys, 0.01) # Discretize\n\nQ = R = I\nL = lqr(sys, Q, R) # Design stabilizing controller\n\nTs = 0.01 # Sample time\nt = 0:Ts:15 # Time vector\ninp(x, t) = -L*x .+ sin(t) # Input function is linear feedback + sin(t)\n\nres = lsim(sys, inp, t)\nres2 = lsim(sys, res.u, t, x0=[1e-6]) # Simulate again, with the same input data but 1e-6 different initial condition\nplot(res)\nplot!(res2)","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"The result indicates that the second simulation looks identical in the beginning, but then diverges exponentially. To understand why, we consider the difference between the two simulations in more detail. The first simulation simulated the closed-loop system","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"dotx = x - Lx + sin(t) = (1-L)x + sin(t) ","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"This system is exponentially stable as long as L is larger than 1. If we collect experimental data for an unstable system under stabilizing feedback, we are actually collecting data from a stable system.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"In the second simulation, we simulate the original open-loop system","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"dotx = x + u + sin(t)","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"where the control input u just happened to be collected from a stabilizing controller. So why didn't this second simulation turn out stable? To understand this, consider what happens when we perturb the initial condition x_0 with a tiny perturbation x_delta = x + delta_x. If we look at the difference tilde x = x - x_delta between a perturbed and an unperturbed simulation, we get","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"dottilde x = dotx - dotx_delta = x + u + sin(t) - (x_delta + u + sin(t)) =  (x - x_delta) = tilde x","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"This is an exponentially unstable system, and unless u depends on tilde x, the difference will grow exponentially. ","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"We can now understand why the second simulation diverges. The input u was collected from a stabilizing controller acting on x, but a small deviation in the state occuring after the data has been collected is not corrected by the controller, and the simulation rapidly diverges.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"What can we do to improve upon this situation? For pure simulation, there is not much we can do. However, when we are simulating a system for the purpose of estimating its parameters, we have a powerful technique available: The solution is to introduce measurement feedback also in the simulation. Put in other words, instead of simulating the unstable system, we perform state estimation on the unstable system using the available measurement data. A state estimator, such as a Kalman filter, has internal measurement feedback that corrects for deviations between the state of the system and the measurement data. For a steady-state Kalman filter in discrete time, this correction looks like","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"hat x_t = hat Ax_t-1 + K(y_t - hat y_t) = hat Ax_t-1 + KC(x_t - hat x_t)","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"i.e., we perform a linear correction based on the difference between the predicted output hat y and the measured output y. The form of this correction should be very familiar, compare it to the equation of a closed-loop control system with reference r:","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"dot x = Ax + Bu quad leftu = L(r - x) right quad dot x = Ax + BL(r - x) ","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"As long as K is chosen so as to make the matrix A-KC exponentially stable, the state estimator will converge to the true state estimate.","category":"page"},{"location":"examples/unstable_systems/#State-estimation-for-system-identification","page":"Identification of unstable systems","title":"State estimation for system identification","text":"","category":"section"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"To make use of a state estimator to estimate the parameters of a dynamical system, we could essentially run a state estimator such as a Kalman filter forward in time, compare the estimated states with the measured data, and compute the gradient of the error with respect to the parameters. This is indeed what is done underneath the hood in the Prediction-Error method (PEM) implemented in the function newpem. This function has a keyword argument focus which defaults to focus = :prediction, but which can also be chosen as focus = :simulation in order to turn the measurement feedback off. However, for unstable systems, the measurement feedback is key to the success of the identification, and any simulation-based algorithm that does not incorporate measurement feedback is prone to divergence.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"The PEM algorithm is used to identify a model for the unstable ball-and-beam system in the tutorial Ball and beam. Towards the end of this tutorial, the performance of the estimated models are compared using progressively longer prediction horizons, but already with a horizon of 20 steps into the future, the prediction performance has degraded significantly due to the instability.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"The prediction-error method has a number of other attractive properties, something that we will explore below.","category":"page"},{"location":"examples/unstable_systems/#Properties-of-the-Prediction-Error-Method","page":"Identification of unstable systems","title":"Properties of the Prediction-Error Method","text":"","category":"section"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"Fundamentally, PEM changes the problem from minimizing a loss based on the simulation performance, to minimizing a loss based on shorter-term predictions.[Ljung][Larsson] There are several benefits of doing so, and this example will highlight two:","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"The loss is often easier to optimize.\nIn addition to an accurate simulator, you also obtain a prediction for the system.\nWith PEM, it's possible to estimate disturbance models.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"The last point will not be illustrated in this tutorial, but we will briefly expand upon it here. Gaussian, zero-mean measurement noise is usually not very hard to handle. Disturbances that affect the state of the system may, however, cause all sorts of havoc on the estimate. Consider wind affecting an aircraft, deriving a statistical and dynamical model of the wind may be doable, but unless you measure the exact wind affecting the aircraft, making use of the model during parameter estimation is impossible. The wind is an unmeasured load disturbance that affects the state of the system through its own dynamics model. Using the techniques illustrated in this tutorial, it's possible to estimate the influence of the wind during the experiment that generated the data and reduce or eliminate the bias it otherwise causes in the parameter estimates.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"We will start by illustrating a common problem with simulation-error minimization. Imagine a pendulum with unknown length that is to be estimated. A small error in the pendulum length causes the frequency of oscillation to change. Over sufficiently large horizon, two sinusoidal signals with different frequencies become close to orthogonal to each other. If some form of squared-error loss is used, the loss landscape will be horribly non-convex in this case, indeed, we will illustrate exactly this below.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"Another case that poses a problem for simulation-error estimation is when the system is unstable or chaotic. A small error in either the initial condition or the parameters may cause the simulation error to diverge and its gradient to become meaningless.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"In both of these examples, we may make use of measurements we have of the evolution of the system to prevent the simulation error from diverging. For instance, if we have measured the angle of the pendulum, we can make use of this measurement to adjust the angle during the simulation to make sure it stays close to the measured angle. Instead of performing a pure simulation, we instead say that we predict the state a while forward in time, given all the measurements until the current time point. By minimizing this prediction rather than the pure simulation, we can often prevent the model error from diverging even though we have a poor initial guess.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"We start by defining a model of the pendulum. The model takes a parameter p = L corresponding to the length of the pendulum.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"using Plots, Statistics, DataInterpolations, LowLevelParticleFilters\n\nTs = 0.01 # Sample time\ntsteps = range(0, stop=20, step=Ts)\n\nx0 = [0.0, 3.0] # Initial angle and angular velocity\n\nfunction pendulum(x, u, p, t) # Pendulum dynamics\n    g = 9.82 # Gravitational constant\n    L = p isa Number ? p : p[1] # Length of the pendulum\n    gL = g / L\n    θ = x[1]\n    dθ = x[2]\n    [dθ\n     -gL * sin(θ)]\nend\nnothing # hide","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"We assume that the true length of the pendulum is L = 1, and generate some data from this system.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"using LowLevelParticleFilters: rk4, rollout\n\ndiscrete_pendulum = rk4(pendulum, Ts) # Discretize the continuous-time dynamics using RK4\n\nfunction simulate(fun, p)\n    x = rollout(fun, x0, tsteps, p; Ts)[1:end-1]\n    y = first.(x) # This is the data we have available for parameter estimation (angle measurement)\n    x, y\nend\n\nx, y = simulate(discrete_pendulum, 1.0) # Simulate with L = 1.0\nplot(tsteps, y, title = \"Pendulum simulation\", label = \"angle\")","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"We also define functions that simulate the system and calculate the loss, given a parameter p corresponding to the length.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"function simloss(p)\n    x,yh = simulate(discrete_pendulum, p)\n    yh .= abs2.(y .- yh)\n    return mean(yh)\nend\nnothing # hide","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"We now look at the loss landscape as a function of the pendulum length:","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"Ls = 0.01:0.01:2\nsimlosses = simloss.(Ls)\nfig_loss = plot(Ls, simlosses,\n    title  = \"Loss landscape\",\n    xlabel = \"Pendulum length\",\n    ylabel = \"MSE loss\",\n    lab    = \"Simulation loss\"\n)","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"This figure is interesting, the loss is of course 0 for the true value L=1, but for values L  1, the overall slope actually points in the wrong direction! Moreover, the loss is oscillatory, indicating that this is a terrible function to optimize, and that we would need a very good initial guess for a local search to converge to the true value. Note, this example is chosen to be one-dimensional in order to allow these kinds of visualizations, and one-dimensional problems are typically not hard to solve, but the reasoning extends to higher-dimensional and harder problems.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"We will now move on to defining a predictor model. Our predictor will be very simple, each time step, we will calculate the error e between the simulated angle theta and the measured angle y. A part of this error will be used to correct the state of the pendulum. The correction we use is linear and looks like Ke = K(y - theta). We have formed what is commonly referred to as a (linear) observer. The Kalman filter is a particular kind of linear observer, where K is calculated based on a statistical model of the disturbances that act on the system. We will stay with a simple, fixed-gain observer here for simplicity.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"To feed the sampled data into the continuous-time simulation, we make use of an interpolator. We also define new functions, predictor that contains the pendulum dynamics with the observer correction, a prediction function that performs the rollout (we're not using the word simulation to not confuse with the setting above) and a loss function.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"y_int = LinearInterpolation(y, tsteps)\n\nfunction predictor(x, u, p, t)\n    g = 9.82\n    L, K, y = p # pendulum length, observer gain and measurements\n    gL = g / L\n    θ = x[1]\n    dθ = x[2]\n    yt = y(t)\n    e = yt - θ\n    [dθ + K * e\n    -gL * sin(θ)]\nend\n\ndiscrete_predictor = rk4(predictor, Ts)\n\nfunction predloss(p)\n    p_full = (p..., y_int)\n    x, yh = simulate(discrete_predictor, p_full)\n    yh .= abs2.(y .- yh)\n    return mean(yh)\nend\n\npredlosses = map(Ls) do L\n    K = 1.0 # Observer feedback gain\n    p = (L, K)\n    predloss(p)\nend\n\nplot!(Ls, predlosses, lab = \"Prediction loss\")","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"Once gain, we look at the loss as a function of the parameter, and this time it looks a lot better. The loss is not convex, but the gradient points in the right direction over a much larger interval. Here, we arbitrarily set the observer gain to K=1, when we use PEM for estimation, will typically let the optimizer learn this parameter as well, which is what is happening inside newpem.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"Now, we might ask ourselves why we used a correct on the form Ke and didn't instead set the angle in the simulation equal to the measurement. The reason is twofold","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"If our prediction of the angle is 100% based on the measurements, the model parameters do not matter for the prediction, and we thus cannot hope to learn their values.\nThe measurement is usually noisy, and we thus want to fuse the predictive power of the model with the information of the measurements. The Kalman filter is an optimal approach to this information fusion under special circumstances (linear model, Gaussian noise).","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"This example has illustrated basic use of the prediction-error method for parameter estimation. In our example, the measurement we had corresponded directly to one of the states, and coming up with an observer/predictor that worked was not too hard. For more difficult cases, we may opt to use a nonlinear observer, such as an extended Kalman filter (EKF) or design a Kalman filter based on a linearization of the system around some operating point.","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"References:","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"[Ljung]: Ljung, Lennart. \"System identification–-Theory for the user\".","category":"page"},{"location":"examples/unstable_systems/","page":"Identification of unstable systems","title":"Identification of unstable systems","text":"[Larsson]: Larsson, Roger, et al. \"Direct prediction-error identification of unstable nonlinear systems applied to flight test data.\"","category":"page"},{"location":"examples/hammerstein_wiener/#Hammerstein-Wiener-estimation-of-nonlinear-belt-drive-system","page":"Nonlinear belt drive","title":"Hammerstein-Wiener estimation of nonlinear belt-drive system","text":"","category":"section"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"In this example, we identify a Wiener model (output nonlinearity only) with data recorded from the belt-drive system depicted below.","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"(Image: Belt drive)","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"The system is described in detail in this report and the data is available on the link downloaded in the code snippet below.","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"The speed sensor available in this system cannot measure the direction, we thus have an absolute-value nonlinearity at the output. The technical report further indicates that there is a low-pass filter on the output, after the nonlinearity. We do not have capabilities of estimating this complicated structure in this package, so we ignore the additional low-pass filter and estimate only the initial linear system and the nonlinearity.","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"The estimation of the Wiener model is performed using the newpem function, see Identification of nonlinear models for more details.","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"using DelimitedFiles, Plots\nusing ControlSystemIdentification, ControlSystemsBase\n\nurl = \"http://www.it.uu.se/research/publications/reports/2017-024/CoupledElectricDrivesDataSetAndReferenceModels.zip\"\nzipfilename = \"/tmp/bd.zip\"\ncd(\"/tmp\")\npath = Base.download(url, zipfilename)\nrun(`unzip -o $path`)\ndata = readdlm(\"/tmp/DATAUNIF.csv\", ',')[2:end, 1:4]\niddatas = map(0:1) do ind\n    u = data[:, 1 + ind]' .|> Float64 # input\n    y = data[:, 3 + ind]' .|> Float64 # output\n    iddata(y, u, 1/50)\nend\n\nplot(plot.(iddatas)...)\n\nd = iddatas[1] # We use one dataset for estimation \ncoherenceplot(d)","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"The coherenceplot, a measure of how well a linear model describes the relation between input and output, unsurprisingly indicates that the system is nonlinear. Before estimating a linear model, it's good practice to inspect this non-parametric measure of linearity.","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"output_nonlinearity = (y, p) -> y .= abs.(y)\n\nnx = 3 # Model order\n\nresults = map(1:40) do _ # This example is a bit more difficult, so we try more random initializations\n    sysh, x0h, opt = newpem(d, nx; output_nonlinearity, show_trace=false, focus=:simulation)\n    (; sysh, x0h, opt)\nend;\n\n(; sysh, x0h, opt) = argmin(r->r.opt.minimum, results) # Find the model with the smallest cost\n\ndv = iddatas[2] # We use the second dataset for validation\nyh = simulate(sysh, dv)\noutput_nonlinearity(yh, nothing) # We need to manually apply the output nonlinearity to the simulation\nplot(dv, lab=[\"Measured nonlinear output\" \"Input\"], layout=(2,1), xlabel=\"Time\")\nplot!(dv.t, yh', lab=\"Simulation\", sp=1, l=:dash)","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"bodeplot(sysh)","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"If everything went as expected, the model should be able to predict the output reasonably well, and the estimated model should have a resonance peak around 20rad/s (compare with Fig. 8 in the report).","category":"page"},{"location":"examples/hammerstein_wiener/","page":"Nonlinear belt drive","title":"Nonlinear belt drive","text":"The dataset consists of two different experiments. In this case we used one for identification and another one for validation. The experiments differ in the amplitude of the input. Ideally, we would use a dataset that combines different amplitudes for training.","category":"page"},{"location":"api/#Exported-functions-and-types","page":"API","title":"Exported functions and types","text":"","category":"section"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [ControlSystemIdentification]\nPrivate = false","category":"page"},{"location":"api/#ControlSystemIdentification.FRD","page":"API","title":"ControlSystemIdentification.FRD","text":"FRD(w, r)\n\nRepresents frequency-response data. w holds the frequency vector and r the response. Methods defined on this type include\n\n+-*\nlength, vec, sqrt\nplot\nfeedback\nfreqvec\ntfest to estimate a rational model\nIndexing in the frequency domain using, e.g., G[1Hz : 5Hz], G[1rad : 5rad]\n\nIf r represents a MIMO frequency response, the dimensions are ny × nu × nω.\n\nAn object frd::FRD can be plotted using plot(frd, hz=false) if using Plots has been called.\n\n\n\n\n\n","category":"type"},{"location":"api/#ControlSystemIdentification.FRD-Tuple{Any, LTISystem}","page":"API","title":"ControlSystemIdentification.FRD","text":"FRD(w, sys::LTISystem)\n\nGenerate a frequency-response data object by evaluating the frequency response of sys at frequencies w.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.Hz","page":"API","title":"ControlSystemIdentification.Hz","text":"Represents frequencies in Herz for indexing of FRD objects: frd[2Hz:10Hz]\n\n\n\n\n\n","category":"type"},{"location":"api/#ControlSystemIdentification.InputOutputData","page":"API","title":"ControlSystemIdentification.InputOutputData","text":"See iddata\n\n\n\n\n\n","category":"type"},{"location":"api/#ControlSystemIdentification.InputOutputFreqData","page":"API","title":"ControlSystemIdentification.InputOutputFreqData","text":"See iddata\n\n\n\n\n\n","category":"type"},{"location":"api/#ControlSystemIdentification.N4SIDStateSpace","page":"API","title":"ControlSystemIdentification.N4SIDStateSpace","text":"N4SIDStateSpace <: AbstractPredictionStateSpace\n\nThe result of statespace model estimation using the n4sid method.\n\nFields:\n\nsys: estimated model in the form of a StateSpace object\nQ: estimated covariance matrix of the states\nR: estimated covariance matrix of the measurements\nS: estimated cross covariance matrix between states and measurements\nK: kalman observer gain\nP: solution to the Riccatti equation\nx: estimated state trajectory\ns: singular values\nfve: Fraction of variance explained by singular values\n\n\n\n\n\n","category":"type"},{"location":"api/#ControlSystemIdentification.PredictionStateSpace","page":"API","title":"ControlSystemIdentification.PredictionStateSpace","text":"PredictionStateSpace{T, ST <: AbstractStateSpace{T}, KT, QT, RT, ST2} <: AbstractPredictionStateSpace{T}\nPredictionStateSpace(sys, K, Q=nothing, R=nothing, S=nothing)\n\nA statespace type that contains an additional Kalman-filter model for prediction purposes.\n\nArguments:\n\nsys: DESCRIPTION\nK: Infinite-horizon Kalman gain\nQ = nothing: Dynamics covariance\nR = nothing: Measurement covariance\nS = nothing: Cross-covariance\n\n\n\n\n\n","category":"type"},{"location":"api/#ControlSystemIdentification.rad","page":"API","title":"ControlSystemIdentification.rad","text":"Represents frequencies in rad/s for indexing of FRD objects: frd[2rad:10rad]\n\n\n\n\n\n","category":"type"},{"location":"api/#ControlSystemIdentification.apply_fun","page":"API","title":"ControlSystemIdentification.apply_fun","text":"apply_fun(fun, d::InputOutputData)\n\nApply fun(y) to all time series y[,u,[x]] ∈ d and return a new iddata with the transformed series.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.ar-Tuple{ControlSystemIdentification.AbstractIdData, Any}","page":"API","title":"ControlSystemIdentification.ar","text":"ar(d::AbstractIdData, na; λ=0, estimator=\\, scaleB=false, stochastic=false)\n\nEstimate an AR transfer function G = 1/A, the AR process is defined as A(z⁻¹)y(t) = e(t)\n\nArguments:\n\nd: IdData, see iddata\nna: order of the model\nλ: λ > 0 can be provided for L₂ regularization\nestimator: e.g. \\,tls,irls,rtls\nscaleB: Whether or not to scale the numerator using the variance of the prediction error.\nstochastic: if true, returns a transfer function with uncertain parameters represented by MonteCarloMeasurements.Particles.\n\nEstimation of AR models using least-squares is known to struggle with heavy measurement noise, using estimator = tls can improve the result in this case.\n\nExample\n\njulia> N = 10000\n10000\n\njulia> e = [-0.2; zeros(N-1)] # noise e\n10000-element Vector{Float64}:\n[...]\n\njulia> G = tf([1, 0], [1, -0.9], 1) # AR transfer function\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n   1.0z\n----------\n1.0z - 0.9\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> y = lsim(G, e, 1:N)[1][:] # Get output of AR transfer function from input noise e\n10000-element Vector{Float64}:\n[...]\n\njulia> Gest = ar(iddata(y), 1) # Estimate AR transfer function from output y\nTransferFunction{Discrete{Float64}, ControlSystemsBase.SisoRational{Float64}}\n          1.0z\n-------------------------\n1.0z - 0.8999999999999998\n\nSample Time: 1.0 (seconds)\nDiscrete-time transfer function model\n\njulia> G ≈ Gest # Test if estimation was correct\ntrue\n\njulia> eest = lsim(1/Gest, y, 1:N)[1][:] # recover the input noise e from output y and estimated transfer function Gest\n10000-element Vector{Float64}:\n[...]\n\njulia> isapprox(eest, e, atol = eps()) # input noise correct recovered\ntrue \n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.arma-Tuple{ControlSystemIdentification.AbstractIdData, Any, Any}","page":"API","title":"ControlSystemIdentification.arma","text":"model = arma(d::AbstractIdData, na, nc; initial_order=20, method=:ls)\n\nEstimate a Autoregressive Moving Average model with na coefficients in the denominator and nc coefficients in the numerator. Returns the model and the estimated noise sequence driving the system.\n\nArguments:\n\nd: iddata\ninitial_order: An initial AR model of this order is used to estimate the residuals\nestimator: A function (A,y)->minimizeₓ(Ax-y) default is \\ but another option is wtls_estimator(1:length(y)-initial_order,na,nc,ones(nc))\n\nSee also estimate_residuals\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.arma_ssa-Tuple{ControlSystemIdentification.AbstractIdData, Any, Any}","page":"API","title":"ControlSystemIdentification.arma_ssa","text":"arma_ssa(d::AbstractIdData, na, nc; L=nothing, estimator=\\, robust=false)\n\nFit arma models using Singular Spectrum Analysis (SSA). A low-rank factorization (svd or robust svd) is performed on the data in order to decompose the signal and the noise. The noise is then used as input to fit an arma model.\n\nArguments:\n\nd:  iddata\nna: number of denominator parameters\nnc: number of numerator parameters\nL:  length of the lag-embedding used to separate signal and noise. nothing corresponds to automatic selection.\nestimator: The function to solve the least squares problem. Examples \\,tls,irls,rtls.\nrobust: Use robust PCA to be resistant to outliers.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.arx-Tuple{ControlSystemIdentification.AbstractIdData, Any, Any}","page":"API","title":"ControlSystemIdentification.arx","text":"Gtf = arx(d::AbstractIdData, na, nb; inputdelay = ones(Int, size(nb)), λ = 0, estimator=\\, stochastic=false)\n\nFit a transfer Function to data using an ARX model and equation error minimization.\n\nnb and na are the number of coefficients of the numerator and denominator polynomials.\n\nInput delay can be added via inputdelay = d, which corresponds to an additional delay of z^-d. An inputdelay = 0 results in a direct term. The highest order of the B polynomial is given by nb + inputdelay - 1.  λ > 0 can be provided for L₂ regularization. estimator defaults to \\ (least squares), alternatives are estimator = tls for total least-squares estimation.  arx(Δt,yn,u,na,nb, estimator=wtls_estimator(y,na,nb) is potentially more robust in the presence of heavy measurement noise. The number of free parameters is na+nb \n\nstochastic: if true, returns a transfer function with uncertain parameters represented by MonteCarloMeasurements.Particles.\n\nSupports MISO estimation by supplying an iddata with a matrix u, with nb = [nb₁, nb₂...] and optional inputdelay = [d₁, d₂...]\n\nThis function supports multiple datasets, provided as a vector of iddata objects.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.arxar-Tuple{InputOutputData, Int64, Union{Int64, AbstractVector{Int64}}, Int64}","page":"API","title":"ControlSystemIdentification.arxar","text":"G, H, e = arxar(d::InputOutputData, na::Int, nb::Union{Int, Vector{Int}}, nd::Int)\n\nEstimate the ARXAR model Ay = Bu + v, where v = He and H = 1/D, using generalized least-squares method. For more information see Söderström - Convergence properties of the generalized least squares identification method, 1974. \n\nArguments:\n\nd: iddata\nna: order of A\nnb: number of coefficients in B, the order is determined by nb + inputdelay - 1. In MISO estimation it takes the form nb = [nb₁, nb₂...]. \nnd: order of D\n\nKeyword Arguments:\n\nH = nothing: prior knowledge about the AR noise model\ninputdelay = ones(Int, size(nb)): optional delay of input, inputdelay = 0 results in a direct term, takes the form inputdelay = [d₁, d₂...] in MISO estimation \nλ = 0: λ > 0 can be provided for L₂ regularization\nestimator = \\: e.g. \\,tls,irls,rtls, the latter three require using TotalLeastSquares\nδmin = 10e-4: Minimal change in the power of e, that specifies convergence.\niterations = 10: maximum number of iterations.\nverbose = false: if true, more information is printed\n\nExample:\n\njulia> N = 500 \n500\n\njulia> sim(G, u) = lsim(G, u, 1:N)[1][:]\nsim (generic function with 1 method)\n\njulia> A = tf([1, -0.8], [1, 0], 1)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n1.0z - 0.8\n----------\n   1.0z\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> B = tf([0, 1], [1, 0], 1)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Int64}}\n1\n-\nz\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> G = minreal(B / A)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n   1.0\n----------\n1.0z - 0.8\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> D = tf([1, 0.7], [1, 0], 1)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n1.0z + 0.7\n----------\n   1.0z\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> H = 1 / D\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n   1.0z\n----------\n1.0z + 0.7\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> u, e = randn(1, N), randn(1, N)\n[...]\n\njulia> y, v = sim(G, u), sim(H * (1/A), e) # simulate process\n[...]\n\njulia> d = iddata(y .+ v, u, 1)\nInputOutput data of length 500 with 1 outputs and 1 inputs\n\njulia> na, nb , nd = 1, 1, 1\n(1, 1, 1)\n\njulia> Gest, Hest, res = arxar(d, na, nb, nd)\n(G = TransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n   0.9987917259291642\n-------------------------\n1.0z - 0.7937837464682017\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model, H = TransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n          1.0z\n-------------------------\n1.0z + 0.7019519225937721\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model, e = [...]\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.autocorplot","page":"API","title":"ControlSystemIdentification.autocorplot","text":"autocorplot(y, Ts, [lags])\n\nPlot the auto correlation of y for lags that default to 1:size(y, 2)÷2.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.coherence-Tuple{ControlSystemIdentification.AbstractIdData}","page":"API","title":"ControlSystemIdentification.coherence","text":"κ = coherence(d; n = length(d)÷10, noverlap = n÷2, window=hamming)\n\nCalculates the magnitude-squared coherence Function. κ close to 1 indicates a good explainability of energy in the output signal by energy in the input signal. κ << 1 indicates that either the system is nonlinear, or a strong noise contributes to the output energy.\n\nκ: Coherence function (not squared) in the form of an FRD.\n\nSee also coherenceplot\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.coherenceplot","page":"API","title":"ControlSystemIdentification.coherenceplot","text":"coherenceplot(d, [(;n=..., noverlap=...); hz=false)\n\nCalculates and plots the (squared) coherence Function κ. κ close to 1 indicates a good explainability of energy in the output signal by energy in the input signal. κ << 1 indicates that either the system is nonlinear, or a strong noise contributes to the output energy.\n\nhz indicates Hertz instead of rad/s\n\nKeyword arguments to coherence are supplied as a named tuple as a second positional argument .\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.crosscorplot","page":"API","title":"ControlSystemIdentification.crosscorplot","text":"crosscorplot(data, [lags])\ncrosscorplot(u, y, Ts, [lags])\n\nPlot the cross correlation between input and output for lags that default to 10% of the length of the dataset on the negative side and 50% on the positive side but no more than 100 on each side.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.detrend-Tuple{AbstractVector}","page":"API","title":"ControlSystemIdentification.detrend","text":"detrend(d::AbstractArray)\ndetrend(d::AbstractIdData)\n\nRemove the mean from d.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.era","page":"API","title":"ControlSystemIdentification.era","text":"era(YY::AbstractArray{<:Any, 3}, Ts, nx::Int, m::Int = 2nx, n::Int = 2nx)\n\nEigenvalue realization algorithm. The algorithm returns a statespace model.\n\nArguments:\n\nYY: Markov parameters (impulse response) size ny × nu × n_time\nTs: Sample time\nnx: Model order\nm: Number of rows in Hankel matrix\nn: Number of columns in Hankel matrix\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.era-2","page":"API","title":"ControlSystemIdentification.era","text":"era(d::AbstractIdData, nx; m = 2nx, n = 2nx, l = 5nx, p = l, λ=0, smooth=false)\nera(ds::Vector{IdData}, nx; m = 2nx, n = 2nx, l = 5nx, p = l, λ=0, smooth=false)\n\nEigenvalue realization algorithm. Uses okid to find the Markov parameters as an initial step.\n\nThe parameter l is likely to require tuning, a reasonable starting point to choose l large enough for the impulse response to have mostly dissipated.\n\nIf a vector of datasets is provided, the Markov parameters estimated from each experiment are averaged before calling era. This allows use of data from multiple experiments to improve the model estimate.\n\nArguments:\n\nnx: Model order\nl: Number of Markov parameters to estimate.\nλ: Regularization parameter (don't overuse this, prefer to make more experiments instead)\nsmooth: If true, the regularization given by λ penalizes curvature in the estimated impulse response.\np: Optionally, delete the first p columns in the internal Hankel matrices to account for initial conditions != 0. If x0 != 0, for era, p defaults to l, while when calling okid directly, p defaults to 0.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.estimate_residuals-Tuple{Any, Any}","page":"API","title":"ControlSystemIdentification.estimate_residuals","text":"estimate_residuals(model, y)\n\nEstimate the residuals driving the dynamics of an ARMA model.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.estimate_x0","page":"API","title":"ControlSystemIdentification.estimate_x0","text":"estimate_x0(sys, d, n = min(length(d), 3 * slowest_time_constant(sys)); fixed = fill(NaN, sys.nx)\n\nEstimate the initial state of the system \n\nArguments:\n\nd: iddata\nn: Number of samples to use.\nfixed: If a vector of the same length as x0 is provided, finite values indicate fixed values that are not to be estimated, while nonfinite values are free.\n\nExample\n\nsys   = ssrand(2,3,4, Ts=1)\nx0    = randn(sys.nx)\nu     = randn(sys.nu, 100)\ny,t,x = lsim(sys, u; x0)\nd     = iddata(y, u, 1)\nx0h   = estimate_x0(sys, d, 8, fixed=[Inf, x0[2], Inf, Inf])\nx0h[2] == x0[2] # Should be exact equality\nnorm(x0-x0h)    # Should be small\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.filter_bank-Tuple{AbstractStateSpace{<:Discrete}, AbstractMatrix}","page":"API","title":"ControlSystemIdentification.filter_bank","text":"filter_bank(basis::AbstractStateSpace{<:Discrete}, signal::AbstractMatrix)\n\nFilter signal through all systems in basis\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.find_na","page":"API","title":"ControlSystemIdentification.find_na","text":"find_na(y::AbstractVector,n::Int)\n\nPlots the RMSE and AIC For model orders up to n. Useful for model selection\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.find_nanb","page":"API","title":"ControlSystemIdentification.find_nanb","text":"find_nanb(d::InputOutputData, na, nb)\n\nPlots the RMSE and AIC For model orders up to na, nb. Useful for model selection. na can be either an integer or a range. The same holds for nb.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.find_similarity_transform","page":"API","title":"ControlSystemIdentification.find_similarity_transform","text":"find_similarity_transform(sys1, sys2)\n\nFind T such that ControlSystemsBase.similarity_transform(sys1, T) == sys2\n\nRef: Minimal state-space realization in linear system theory: an overview, B. De Schutter\n\njulia> T = randn(3,3);\n\njulia> sys1 = ssrand(1,1,3);\n\njulia> sys2 = ControlSystemsBase.similarity_transform(sys1, T);\n\njulia> T2 = find_similarity_transform(sys1, sys2);\n\njulia> T2 ≈ T\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.freqvec-Tuple{Any, AbstractVector}","page":"API","title":"ControlSystemIdentification.freqvec","text":"freqvec(h, k)\n\nReturn a frequency vector of length k for systems with sample time h.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.getARXregressor-Tuple{AbstractVector, AbstractVecOrMat, Any, Any}","page":"API","title":"ControlSystemIdentification.getARXregressor","text":"getARXregressor(y::AbstractVector,u::AbstractVecOrMat, na, nb; inputdelay = ones(Int, size(nb)))\n\nReturns a shortened output signal y and a regressor matrix A such that the least-squares ARX model estimate of order na,nb is y\\A\n\nReturn a regressor matrix used to fit an ARX model on, e.g., the form A(z)y = B(z)u with output y and input u where the order of autoregression is na, the order of input moving average is nb and an optional input delay inputdelay. Caution, changing the input delay changes the order to nb + inputdelay - 1. An inputdelay = 0 results in a direct term. \n\nExample\n\nA     = [1,2*0.7*1,1] # A(z) coeffs\nB     = [10,5] # B(z) coeffs\nu     = randn(100) # Simulate 100 time steps with Gaussian input\ny     = filt(B,A,u)\nyr,A  = getARXregressor(y,u,3,2) # We assume that we know the system order 3,2\nx     = A\\yr # Estimate model polynomials\nplot([yr A*x], lab=[\"Signal\" \"Prediction\"])\n\nFor nonlinear ARX-models, see BasisFunctionExpansions.jl. See also arx\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.getARregressor-Tuple{AbstractVector, Any}","page":"API","title":"ControlSystemIdentification.getARregressor","text":"yt,A = getARregressor(y::AbstractVector, na)\n\nReturns values such that x = A\\yt. See getARXregressor for more details.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.iddata","page":"API","title":"ControlSystemIdentification.iddata","text":"iddata(y,       Ts = nothing)\niddata(y, u,    Ts = nothing)\niddata(y, u, x, Ts = nothing)\n\nCreate a time-domain identification data object. \n\nArguments\n\ny::AbstractArray: output data (required)\nu::AbstractArray: input data (if available)\nx::AbstractArray: state data (if available)\nTs::Union{Real,Nothing} = nothing: optional sample time\n\nIf the time-series are multivariate, time is in the last dimension, i.e., the sizes of the arrays are (num_variables, num_timepoints) (see examples below).\n\nOperations on iddata\n\ndetrend\nprefilter\nresample\nappend two along the time dimension [d1 d2] (only do this if the state of the system at the end of d1 is close to the state at the beginning of d2)\nindex time series d[output_index, input_index]\nindex the time axis with indices d[time_indices]\nindex the time axis with seconds d[3Sec:12Sec] (using ControlSystemIdentification: Sec)\naccess number of inputs, outputs and sample time: d.nu, d.ny, d.Ts\naccess the time time vector d.t\npremultiply to scale outputs C * d. Scaling the outputs of a multiple-output system to have roughly the same size is usually recommended before estimating a model in case they have different magnitudes.\npostmultiply to scale inputs d * B\nwritedlm\nramp_in, ramp_out\nplot\nspecplot\ncrosscorplot\n\nExamples\n\njulia> iddata(randn(10))\nOutput data of length 10 with 1 outputs, Ts = nothing\n\njulia> iddata(randn(10), randn(10), 1)\nInputOutput data of length 10, 1 outputs, 1 inputs, Ts = 1\n\njulia> d = iddata(randn(2, 10), randn(3, 10), 0.1)\nInputOutput data of length 10, 2 outputs, 3 inputs, Ts = 0.1\n\njulia> [d d] # Concatenate along time\nInputOutput data of length 20, 2 outputs, 3 inputs, Ts = 0.1\n\njulia> d[1:3]\nInputOutput data of length 3, 2 outputs, 3 inputs, Ts = 0.1\n\njulia> d.nu\n3\n\njulia> d.t # access time vector\n0.0:0.1:0.9\n\nUse of multiple datasets\n\nSome estimation methods support the use of multiple datasets to estimate a model. In this case, the datasets are provided as a vector of iddata objects. The methods that currently support this are:\n\narx\nera\n\nSeveral of the other estimation methods can be made to accept multiple datasets with minor modifications.\n\nIn some situations, multiple datasets can also be handled by concatination. For this to be a good idea, the state of the system at the end of one data set must be close to the state at the beginning of the next, e.g., all experiments start and end at the same operating point.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.iddata-Tuple{AbstractArray, AbstractArray, AbstractVector}","page":"API","title":"ControlSystemIdentification.iddata","text":"iddata(y::AbstractArray, u::AbstractArray, w::AbstractVector)\n\nCreate a frequency-domain input-output data object. w is expected to be in rad/s.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.iddata-Tuple{ControlSystemsBase.SimResult}","page":"API","title":"ControlSystemIdentification.iddata","text":"iddata(res::ControlSystemsBase.SimResult)\n\nCreate an identification-data object directly from a simulation result.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.impulseest-Tuple{ControlSystemIdentification.AbstractIdData, Any}","page":"API","title":"ControlSystemIdentification.impulseest","text":"ir, t, Σ = impulseest(d::AbstractIdData, n; λ=0, estimator=ls)\n\nEstimates the system impulse response by fitting an n:th order FIR model. Returns impulse-response estimate, time vector and covariance matrix.\n\nThis function only supports single-output data, use okid for multi-output data.\n\nSee also impulseestplot and okid.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.impulseestplot","page":"API","title":"ControlSystemIdentification.impulseestplot","text":"impulseestplot(data,n; σ = 2)\n\nEstimates the system impulse response by fitting an n:th order FIR model and plots the result with a 95% (2σ) confidence band. Note, the confidence bound is drawn around zero, i.e., it is drawn such that one can determine whether or not the impulse response is significantly different from zero.\n\nThis method only supports single-output data, use okid for multi-output data.\n\nSee also impulseest and okid.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.kautz-Tuple{AbstractVector, Any}","page":"API","title":"ControlSystemIdentification.kautz","text":"kautz(a::Vector, h)\n\nConstruct a discrete-time Kautz basis with poles at a amd sample time h.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.laguerre-Tuple{Any, Any}","page":"API","title":"ControlSystemIdentification.laguerre","text":"laguerre(a::Number, Nq)\n\nConstruct a Laguerre basis of length Nq with poles at -a.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.laguerre_id-Tuple{Any, Any, Any}","page":"API","title":"ControlSystemIdentification.laguerre_id","text":"laguerre_id(a::Number, Nq, Ts)\n\nConstruct a discrete-time Laguerre basis of length Nq with poles at -a for system identification.\n\nNOTE: for large Nq, this basis may be numerically ill-conditioned. Consider applying balance_statespace to the resulting basis.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.laguerre_oo-Tuple{Number, Any}","page":"API","title":"ControlSystemIdentification.laguerre_oo","text":"laguerre_oo(a::Number, Nq)\n\nConstruct an output orthogonalized Laguerre basis of length Nq with poles at -a.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.minimum_phase-Tuple{TransferFunction{Continuous}}","page":"API","title":"ControlSystemIdentification.minimum_phase","text":"minimum_phase(G)\n\nMove zeros and poles of G from the unstable half plane to the stable. If G is a statespace system, it's converted to a transfer function first. This can incur loss of precision.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.model_spectrum-Tuple{Any, Any, Vararg{Any}}","page":"API","title":"ControlSystemIdentification.model_spectrum","text":"model_spectrum(f, h, args...; kwargs...)\n\nArguments:\n\nf: the model-estimation function, e.g., ar,arma\nh: The sample time\nargs: arguments to f\nkwargs: keyword arguments to f\n\nExample:\n\nusing ControlSystemIdentification, DSP\nT = 1000\ns = sin.((1:T) .* 2pi/10)\nS1 = spectrogram(s,window=hanning)\nestimator = model_spectrum(ar,1,2)\nS2 = spectrogram(s,estimator,window=rect)\nplot(plot(S1),plot(S2)) # Requires the package LPVSpectral.jl\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.modelfit-Tuple{Any, Any}","page":"API","title":"ControlSystemIdentification.modelfit","text":"modelfit(y, yh)\n\nCompute the model fit of yh to y as a percentage, sometimes referred to as the normalized root mean square error (NRMSE).\n\ntextmodelfit(y haty) = 100 left(1 - fracsqrttextSSE(y - haty)sqrttextSSE(y - bary)right)\n\nAn output of 100 indicates a perfect fit, an output of 0 indicates that the fit is no better than the mean if the data. Negative values are possible if the prediction is worse than predicting the mean of the data.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.n4sid-Union{Tuple{InputOutputData}, Tuple{F3}, Tuple{F2}, Tuple{F1}, Tuple{InputOutputData, Any}} where {F1, F2, F3}","page":"API","title":"ControlSystemIdentification.n4sid","text":"res = n4sid(data, r=:auto; verbose=false)\n\nEstimate a statespace model using the n4sid method. Returns an object of type N4SIDStateSpace where the model is accessed as res.sys.\n\nImplements the simplified algorithm (alg 2) from \"N4SID: Subspace Algorithms for the Identification of Combined Deterministic Stochastic Systems\" PETER VAN OVERSCHEE and BART DE MOOR\n\nThe frequency weighting is borrowing ideas from \"Frequency Weighted Subspace Based System Identification in the Frequency Domain\", Tomas McKelvey 1996. In particular, we apply the output frequency weight matrix (Fy) as it appears in eqs. (16)-(18).\n\nArguments:\n\ndata: Identification data data = iddata(y,u)\nr: Rank of the model (model order)\nverbose: Print stuff?\nWf: A frequency-domain model of measurement disturbances. To focus the attention of the model on a narrow frequency band, try something like Wf = Bandstop(lower, upper, fs=1/Ts) to indicate that there are disturbances outside this band.\ni: Algorithm parameter, generally no need to tune this\nγ: Set this to a value between (0,1) to stabilize unstable models such that the largest eigenvalue has magnitude γ.\nzeroD: defaults to false\n\nSee also the newer implementation subspaceid which allows you to choose between different weightings (n4sid being one of them). A more accurate prediciton model can sometimes be obtained using newpem, which is also unbiased for closed-loop data.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.newpem-Union{Tuple{RE}, Tuple{F}, Tuple{Any, Any}} where {F, RE}","page":"API","title":"ControlSystemIdentification.newpem","text":"sys, x0, res = newpem(\n    d,\n    nx;\n    zeroD  = true,\n    focus  = :prediction,\n    stable = true,\n    sys0   = subspaceid(d, nx; zeroD, focus, stable),\n    metric = abs2,\n    regularizer = (p, P) -> 0,\n    output_nonlinearity = nothing,\n    input_nonlinearity = nothing,\n    nlp = nothing,\n    optimizer = BFGS(\n        linesearch = LineSearches.BackTracking(),\n    ),\n    store_trace = true,\n    show_trace  = true,\n    show_every  = 50,\n    iterations  = 10000,\n    time_limit  = 100,\n    x_tol       = 0,\n    f_abstol    = 0,\n    g_tol       = 1e-12,\n    f_calls_limit = 0,\n    g_calls_limit = 0,\n    allow_f_increases = false,\n)\n\nA new implementation of the prediction-error method (PEM). Note that this is an experimental implementation and subject to breaking changes not respecting semver.\n\nThe prediction-error method is an iterative, gradient-based optimization problem, as such, it can be extra sensitive to signal scaling, and it's recommended to perform scaling to d before estimation, e.g., by pre and post-multiplying with diagonal matrices d̃ = Dy*d*Du, and apply the inverse scaling to the resulting system. In this case, we have\n\nD_y y = G D_u u  y = D_y^-1 G D_u u\n\nhence G = Dy \\ G̃ * Du where $ G̃ $ is the plant estimated for the scaled iddata. Example:\n\nDy = Diagonal(1 ./ vec(std(d.y, dims=2))) # Normalize variance\nDu = Diagonal(1 ./ vec(std(d.u, dims=2))) # Normalize variance\nd̃ = Dy * d * Du\n\nIf a manually provided initial guess sys0, this must also be scaled appropriately.\n\nArguments:\n\nd: iddata\nnx: Model order\nzeroD: Force zero D matrix\nstable if true, stability of the estimated system will be enforced by eigenvalue reflection using schur_stab with ϵ=1/100 (default). If stable is a real value, the value is used instead of the default ϵ.\nsys0: Initial guess, if non provided, subspaceid is used as initial guess.\nfocus: prediction or :simulation. If :simulation, the K matrix will be zero.\noptimizer: One of Optim's optimizers\nmetric: The metric used to measure residuals. Try, e.g., abs for better resistance to outliers.\n\nThe rest of the arguments are related to Optim.Options.\n\nregularizer: A function of the parameter vector and the corresponding PredictionStateSpace/StateSpace system that can be used to regularize the estimate.\noutput_nonlinearity: A function of (y::Vector, p) that operates on the output signal at a single time point, yₜ, and modifies it in-place. See below for details. p is a vector of estimated parameters that can be optimized.\ninput_nonlinearity: A function of (u::Matrix, p) that operates on the entire input signal u at once and modifies it in-place. See below for details. p is a vector of estimated parameters that is shared with output_nonlinearity.\nnlp: Initial guess vector for nonlinear parameters. If output_nonlinearity is provided, this can optionally be provided.\n\nNonlinear estimation\n\nNonlinear systems on Hammerstein-Wiener form, i.e., systems with a static input nonlinearity and a static output nonlinearity with a linear system inbetween, can be estimated as long as the nonlinearities are known. The procedure is\n\nIf there is a known input nonlinearity, manually apply the input nonlinearity to the input signal u before estimation, i.e., use the nonlinearly transformed input in the iddata object d. If the input nonlinearity has unknown parameters, provide the input nonlinearity as a function using the keyword argument input_nonlinearity to newpem. This function is expected to operate on the entire (matrix) input signal u and modify it in-place.\nIf the output nonlinearity is invertible, apply the inverse to the output signal y before estimation similar to above.\nIf the output nonlinearity is not invertible, provide the nonlinear output transformation as a function using the keyword argument output_nonlinearity to newpem. This function is expected to operate on the (vector) output signal y and modify it in-place. Example:\n\nfunction output_nonlinearity(y, p)\n    y[1] = y[1] + p[1]*y[1]^2       # Note how the incoming vector is modified in-place\n    y[2] = abs(y[2])\nend\n\nPlease note, y = f(y) does not change y in-place, but creates a new vector y and assigns it to the variable y. This is not what we want here.\n\nThe second argument to input_nonlinearity and output_nonlinearity is an (optional) vector of parameters that can be optimized. To use this option, pass the keyword argument nlp to newpem with a vector of initial guesses for the nonlinear parameters. The nonlinear parameters are shared between output and input nonlinearities, i.e., these two functions will receive the same vector of parameters.\n\nThe result of this estimation is the linear system without the nonlinearities.\n\nExample\n\nThe following simulates data from a linear system and estimates a model. For an example of nonlinear identification, see the documentation.\n\nusing ControlSystemIdentification, ControlSystemsBase Plots\nG = DemoSystems.doylesat()\nT = 1000  # Number of time steps\nTs = 0.01 # Sample time\nsys = c2d(G, Ts)\nnx = sys.nx\nnu = sys.nu\nny = sys.ny\nx0 = zeros(nx) # actual initial state\nsim(sys, u, x0 = x0) = lsim(sys, u; x0)[1]\n\nσy = 1e-1 # Noise covariance\n\nu  = randn(nu, T)\ny  = sim(sys, u, x0)\nyn = y .+ σy .* randn.() # Add measurement noise\nd  = iddata(yn, u, Ts)\n\nsysh, x0h, opt = ControlSystemIdentification.newpem(d, nx, show_every=10)\n\nplot(\n    bodeplot([sys, sysh]),\n    predplot(sysh, d, x0h), # Include the estimated initial state in the prediction\n)\n\nThe returned model is of type PredictionStateSpace and contains the field sys with the system model, as well as covariance matrices and estimated Kalman gain for a Kalman filter.\n\nSee also nonlinear_pem.\n\nExtended help\n\nThis implementation uses a tridiagonal parametrization of the A-matrix that has been shown to be favourable from an optimization perspective.¹ The initial guess sys0 is automatically transformed to a special tridiagonal modal form.  [1]: Mckelvey, Tomas & Helmersson, Anders. (1997). State-space parametrizations of multivariable linear systems using tridiagonal matrix forms.\n\nThe parameter vector used in the optimization takes the following form\n\np = [trivec(A); vec(B); vec(C); vec(D); vec(K); vec(x0)]\n\nWhere ControlSystemIdentification.trivec vectorizes the -1,0,1 diagonals of A. If focus = :simulation, K is omitted, and if zeroD = true, D is omitted.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.noise_model-Tuple{AbstractPredictionStateSpace}","page":"API","title":"ControlSystemIdentification.noise_model","text":"noise_model(sys::AbstractPredictionStateSpace)\n\nReturn a model of the noise driving the system, v, in\n\nx = Ax + Bu + Kv\ny = Cx + Du + v\n\nThe model neglects u and is given by\n\nx = Ax + Kv\ny = Cx + v\n\nAlso called the \"innovation form\". This function calls ControlSystemsBase.innovation_form.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.okid","page":"API","title":"ControlSystemIdentification.okid","text":"H = okid(d::AbstractIdData, nx, l = 5nx; p = 1, λ=0, estimator = /)\n\nObserver Kalman filter identification. Returns the Markov parameters (impulse response) H size ny × nu × (l+1).\n\nThe parameter l is likely to require tuning, a reasonable starting point to choose l large enough for the impulse response to have mostly dissipated.\n\nArguments:\n\nnx: Model order\nl: Number of Markov parameters to estimate (length of impulse response).\nλ: Regularization parameter\nsmooth: If true, the regularization given by λ penalizes curvature in the estimated impulse response. If era is to be used after okid, favor a small λ with smooth=true, but if the impulse response is to be inspected by eye, a larger smoothing can yield a visually more accurate estimate of the impulse response.\np: Optionally, delete the first p columns in the internal Hankel matrices to account for initial conditions != 0. If x0 != 0, try setting p around the same value as l.\nestimator: Function to use for estimating the Markov parameters. Defaults to / (least squares), but can also be a robust option such as TotalLeastSquares.irls / flts or TotalLeastSquares.tls for a total least-squares solutoins (errors in variables).\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.pem-Tuple{Any}","page":"API","title":"ControlSystemIdentification.pem","text":"This function is deprecated, see newpem\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.plr-Tuple{ControlSystemIdentification.AbstractIdData, Any, Any, Any}","page":"API","title":"ControlSystemIdentification.plr","text":"G, Gn = plr(d::AbstractIdData,na,nb,nc; initial_order = 20)\n\nPerform pseudo-linear regression to estimate a model on the form Ay = Bu + Cw The residual sequence is estimated by first estimating a high-order arx model, whereafter the estimated residual sequence is included in a second estimation problem. The return values are the estimated system model, and the estimated noise model. G and Gn will always have the same denominator polynomial.\n\narmax is an alias for plr. See also pem, ar, arx\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.prediction_error-Tuple{AbstractStateSpace, ControlSystemIdentification.AbstractIdData, Vararg{Any}}","page":"API","title":"ControlSystemIdentification.prediction_error","text":"e = prediction_error(sys::AbstractStateSpace, d::AbstractIdData, args...; kwargs...)\n\nReturn the prediction errors `d.y - predict(sys, d, ...)\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.predplot","page":"API","title":"ControlSystemIdentification.predplot","text":"predplot(sys, data, x0=:estimate; ploty=true, plote=false, h=1, sysname=\"\")\n\nPlot system h-step prediction and measured output to compare them.\n\nBy default, the initial condition x0 is estimated using the data. To start the simulation from the origin, provide x0 = :zero or x0 = zeros(sys.nx).\n\nploty determines whether or not to plot the measured signal\nplote determines whether or not to plot the residual\nh is the prediction horizon.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.prefilter-Tuple{Any, InputOutputData}","page":"API","title":"ControlSystemIdentification.prefilter","text":"prefilter(f, d::InputOutputData)\n\nApply filter coefficients to identification data\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.prefilter-Tuple{ControlSystemIdentification.AbstractIdData, DSP.Filters.FilterType}","page":"API","title":"ControlSystemIdentification.prefilter","text":"prefilter(d::AbstractIdData, responsetype::FilterType)\n\nFilter both input and output of the identification data using zero-phase filtering (filtfilt). Since both input and output is filtered, linear identification will not be affected in any other way than to focus the fit on the selected frequency range, i.e. the range that has high gain in the provided filter. Note, if the system that generated d is nonlinear, identification might be severely impacted by this transformation. Verify linearity with, e.g., coherenceplot.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.prefilter-Tuple{ControlSystemIdentification.AbstractIdData, Number, Number}","page":"API","title":"ControlSystemIdentification.prefilter","text":"prefilter(d::AbstractIdData, l::Number, u::Number)\n\nFilter input and output with a bandpass filter between l and u Hz. If l = 0 a lowpass filter will be used, and if u = Inf a highpass filter will be used.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.ramp_in-Tuple{InputOutputData, Int64}","page":"API","title":"ControlSystemIdentification.ramp_in","text":"ramp_in(d::InputOutputData, h::Int; rev = false)\n\nMultiply the initial h samples of input and output signals with a linearly increasing ramp.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.ramp_out-Tuple{InputOutputData, Int64}","page":"API","title":"ControlSystemIdentification.ramp_out","text":"ramp_out(d::InputOutputData, h::Int)\n\nMultiply the final h samples of input and output signals with a linearly decreasing  ramp.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.residualplot","page":"API","title":"ControlSystemIdentification.residualplot","text":"residualplot(model, data)\n\nPlot residual autocorrelation and input-residual correlation.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.schur_stab-Union{Tuple{AbstractMatrix{T}}, Tuple{T}, Tuple{AbstractMatrix{T}, Any}} where T","page":"API","title":"ControlSystemIdentification.schur_stab","text":"schur_stab(A::AbstractMatrix{T}, ϵ = 0.01)\n\nStabilize the eigenvalues of discrete-time matrix A by transforming A to complex Schur form and projecting unstable eigenvalues 1-ϵ < λ ≤ 2 into the unit disc. Eigenvalues > 2 are set to 0.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.simplot","page":"API","title":"ControlSystemIdentification.simplot","text":"simplot(sys, data, x0=:estimate; ploty=true, plote=false, sysname=\"\")\n\nPlot system simulation and measured output to compare them.\n\nBy default, the initial condition x0 is estimated using the data. To start the simulation from the origin, provide x0 = :zero or x0 = zeros(sys.nx).\n\nploty determines whether or not to plot the measured signal\nplote determines whether or not to plot the residual\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.specplot","page":"API","title":"ControlSystemIdentification.specplot","text":"specplot(d::IdData, args...; kwargs...)\n\nPlot a spectrogram of the input and output timeseries. See also welchplot.\n\nAdditional arguments are passed along to DSP.spectrogram.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.subspaceid-Tuple{FRD, Real, Vararg{Any}}","page":"API","title":"ControlSystemIdentification.subspaceid","text":"model, x0 = subspaceid(frd::FRD, Ts, args...; estimate_x0 = false, bilinear_transform = false, kwargs...)\n\nIf a frequency-reponse data object is supplied\n\nThe FRD will be automatically converted to an InputOutputFreqData\nestimate_x0 is by default set to 0.\nbilinear_transform transform the frequency vector to discrete time, see note below.\n\nNote: if the frequency-response data comes from a frequency-response analysis, a bilinear transform of the data is required before estimation. This transform will be applied if bilinear_transform = true.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.subspaceid-Union{Tuple{InputOutputData}, Tuple{F3}, Tuple{F2}, Tuple{F1}, Tuple{InputOutputData, Any}} where {F1, F2, F3}","page":"API","title":"ControlSystemIdentification.subspaceid","text":"subspaceid(\n    data::InputOutputData,\n    nx = :auto;\n    verbose = false,\n    r = nx === :auto ? min(length(data) ÷ 20, 20) : nx + 10, # the maximal prediction horizon used\n    s1 = r, # number of past outputs\n    s2 = r, # number of past inputs\n    W = :MOESP,\n    zeroD = false,\n    stable = true, \n    focus = :prediction,\n    svd::F1 = svd!,\n    scaleU = true,\n    Aestimator::F2 = \\,\n    Bestimator::F3 = \\,\n    weights = nothing,\n)\n\nEstimate a state-space model using subspace-based identification. Several different subspace-based algorithms are available, and can be chosen using the W keyword. Options are :MOESP, :CVA, :N4SID, :IVM.\n\nRef: Ljung, Theory for the user.\n\nResistance against outliers can be improved by supplying a custom factorization algorithm and replacing the internal least-squares estimators. See the documentation for the keyword arguments svd, Aestimator, and Bestimator below.\n\nThe returned model is of type N4SIDStateSpace and contains the field sys with the system model, as well as covariance matrices for a Kalman filter.\n\nArguments:\n\ndata: Identification data iddata\nnx: Rank of the model (model order)\nverbose: Print stuff?\nr: Prediction horizon. The model may perform better on simulation if this is made longer, at the expense of more computation time.\ns1: past horizon of outputs\ns2: past horizon of inputs\nW: Weight type, choose between :MOESP, :CVA, :N4SID, :IVM\nzeroD: Force the D matrix to be zero.\nstable: Stabilize unstable system using eigenvalue reflection.\nfocus: :prediction or simulation\nsvd: The function to use for svd. For resistance against outliers, consider using TotalLeastSquares.rpca to preprocess the data matrix before applying svd, like svd = A->svd!(rpca(A)[1]).\nscaleU: Rescale the input channels to have the same energy.\nAestimator: Estimator function used to estimate A,C. The default is `, i.e., least squares, but robust estimators, such asirls, flts, rtls` from TotalLeastSquares.jl, can be used to gain resistance against outliers.\nBestimator: Estimator function used to estimate B,D. Weighted estimation can be eachieved by passing wls from TotalLeastSquares.jl together with the weights keyword argument.\nweights: A vector of weights can be provided if the Bestimator is wls. \n\nExtended help\n\nA more accurate prediciton model can sometimes be obtained using newpem, which is also unbiased for closed-loop data (subspaceid is biased for closed-loop data, see example in the docs). The prediction-error method is iterative and generally more expensive than subspaceid, and uses this function (by default) to form the initial guess for the optimization.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.subspaceid-Union{Tuple{InputOutputFreqData}, Tuple{F3}, Tuple{F2}, Tuple{F1}, Tuple{InputOutputFreqData, Real}, Tuple{InputOutputFreqData, Real, Union{Int64, Symbol}}} where {F1, F2, F3}","page":"API","title":"ControlSystemIdentification.subspaceid","text":"model, x0 = subspaceid(data::InputOutputFreqData,\n    Ts = data.Ts,\n    nx = :auto;\n    cont = false,\n    verbose = false,\n    r = nx === :auto ? min(length(data) ÷ 20, 20) : 2nx, # Internal model order\n    zeroD = false,\n    estimate_x0 = true,\n    stable = true, \n    svd = svd!,\n    Aestimator = \\,\n    Bestimator = \\,\n    weights = nothing\n)\n\nEstimate a state-space model using subspace-based identification in the frequency domain.\n\nIf results are poor, try modifying r, in particular if the amount of data is low.\n\nSee the docs for an example.\n\nArguments:\n\ndata: A frequency-domain identification data object.\nTs: Sample time at which the data was collected\nnx: Desired model order, an interer or :auto.\ncont: Return a continuous-time model? A bilinear transformation is used to convert the estimated discrete-time model, see function d2c.\nverbose: Print stuff?\nr: Internal model order, must be ≥ nx.\nzeroD: Force the D matrix to be zero.\nestimate_x0: Esimation of extra parameters to account for initial conditions. This may be required if the data comes from the fft of time-domain data, but may not be required if the data is collected using frequency-response analysis with exactly periodic input and proper handling of transients.\nstable: For the model to be stable (uses schur_stab).\nsvd: The svd function to use.\nAestimator: The estimator of the A matrix (and initial C-matrix).\nBestimator: The estimator of B/D and C/D matrices.\nweights: An optional vector of frequency weights of the same length as the number of frequencies in `data.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.tfest","page":"API","title":"ControlSystemIdentification.tfest","text":"H, N = tfest(data, σ = 0.05)\n\nEstimate a transfer function model using the Correlogram approach. Both H and N are of type FRD (frequency-response data).\n\nσ determines the width of the Gaussian window applied to the estimated correlation functions before FFT. A larger σ implies less smoothing.\nH = Syu/Suu             Process transfer function\nN = Sy - |Syu|²/Suu     Noise PSD\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.tfest-2","page":"API","title":"ControlSystemIdentification.tfest","text":"tfest(\n    data::FRD,\n    p0,\n    link = log ∘ abs;\n    freq_weight = sqrt(data.w[1]*data.w[end]),\n    refine = true,\n    opt = BFGS(),\n    opts = Optim.Options(\n        store_trace       = true,\n        show_trace        = true,\n        show_every        = 1,\n        iterations        = 100,\n        allow_f_increases = false,\n        time_limit        = 100,\n        x_tol             = 0,\n        f_tol             = 0,\n        g_tol             = 1e-8,\n        f_calls_limit     = 0,\n        g_calls_limit     = 0,\n    ),\n)\n\nFit a parametric transfer function to frequency-domain data.\n\nThe initial pahse of the optimization solves\n\noperatornameminimize_BA Bl - A\n\nand the second stage (if refine=true) solves \n\noperatornameminimize_BA textlinkleft(dfracBAright) - textlinkleft(lright)\n\n(abs2(link(B/A) - link(l)))\n\nArguments:\n\ndata: An FRD onbject with frequency domain data.\np0: Initial parameter guess. Can be a NamedTuple or ComponentVector with fields b,a specifying numerator and denominator as they appear in the call to tf, i.e., (b = [1.0], a = [1.0,1.0,1.0]). Can also be an instace of TransferFunction.\nlink: By default, phase information is discarded in the fitting. To include phase, change to link = log.\nfreq_weight: Apply weighting with the inverse frequency. The value determines the cutoff frequency before which the weight is constant, after which the weight decreases linearly. Defaults to the geometric mean of the smallest and largest frequency.\nrefine: Indicate whether or not a second optimization stage is performed to refine the results of the first.\nopt: The Optim optimizer to use.\nopts: Optim.Options controlling the solver options.\n\nSee also minimum_phase to transform a possibly non-minimum phase system to minimum phase.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.tfest-Union{Tuple{M}, Tuple{FRD, AbstractStateSpace}} where M","page":"API","title":"ControlSystemIdentification.tfest","text":"tfest(data::FRD, basis::AbstractStateSpace; \n    freq_weight = 1 ./ (data.w .+ data.w[2]),\n    opt = BFGS(),\n    metric::M = abs2,\n    opts = Optim.Options(\n        store_trace       = true,\n        show_trace        = true,\n        show_every        = 50,\n        iterations        = 1000000,\n        allow_f_increases = false,\n        time_limit        = 100,\n        x_tol             = 1e-5,\n        f_tol             = 0,\n        g_tol             = 1e-8,\n        f_calls_limit     = 0,\n        g_calls_limit     = 0,\n)\n\nFit a parametric transfer function to frequency-domain data using a pre-specified basis.\n\nArguments:\n\ndata: An FRD onbject with frequency domain data.\n\nfunction kautz(a::AbstractVector)\n\nbasis: A basis for the estimation. See, e.g., laguerre, laguerre_oo, kautz\nfreq_weight: A vector of weights per frequency. The default is approximately 1/f. \nopt: The Optim optimizer to use.\nopts: Optim.Options controlling the solver options.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemIdentification.welchplot","page":"API","title":"ControlSystemIdentification.welchplot","text":"welchplot(d::IdData, args...; kwargs...)\n\nPlot a Wlch peridogram of the input and output timeseries. See also specplot.\n\nAdditional arguments are passed along to DSP.welch_pgram.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemIdentification.wtls_estimator","page":"API","title":"ControlSystemIdentification.wtls_estimator","text":"wtls_estimator(y,na,nb, σu=0)\n\nCreate an estimator function for estimation of arx models in the presence of measurement noise. If the noise variance on the input σu (model errors) is known, this can be specified for increased accuracy.\n\n\n\n\n\n","category":"function"},{"location":"api/#DSP.Filters.resample-Tuple{AbstractStateSpace{<:Discrete}, AbstractMatrix, Real}","page":"API","title":"DSP.Filters.resample","text":"DSP.resample(sys::AbstractStateSpace{<:Discrete}, Qd::AbstractMatrix, newh::Real)\n\nChange sample time of covariance matrix Qd beloning to sys to newh. This function does not handle the measurement covariance, how to do this depends on context. If the faster sampled signal has the same measurement noise, no change should be made. If the slower sampled signal was downsampled with filtering, the measurement covariance should be increased if the system is changed to a faster sample rate. To maintain the frequency response of the system, the measurement covariance should be modified accordinly.\n\nArguments:\n\nsys: A discrete-time system that has dynamics noise covariance matric Qd.\nQd: Covariance matrix of dynamics noise.\nnewh: The new sample time.\n\n\n\n\n\n","category":"method"},{"location":"api/#DSP.Filters.resample-Tuple{AbstractStateSpace{<:Discrete}, Real}","page":"API","title":"DSP.Filters.resample","text":"resample(sys::AbstractStateSpace{<:Discrete}, newh::Real)\n\nChange sample-time of sys to newh.\n\n\n\n\n\n","category":"method"},{"location":"api/#DSP.Filters.resample-Tuple{ControlSystemIdentification.AbstractIdData, Any}","page":"API","title":"DSP.Filters.resample","text":"dr = resample(d::InputOutputData, f)\n\nResample iddata d with fraction f, e.g., f = fs_new / fs_original.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.simulate","page":"API","title":"LowLevelParticleFilters.simulate","text":"simulate(sys, u, x0 = nothing)\nsimulate(sys, d, x0 = nothing)\n\nSee also simplot, predict\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.predict-Tuple{Any, ControlSystemIdentification.AbstractIdData, Vararg{Any}}","page":"API","title":"StatsAPI.predict","text":"predict(sys, d::AbstractIdData, args...)\npredict(sys, y, u, x0 = nothing)\n\nSee also predplot\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict-Tuple{TransferFunction, Any}","page":"API","title":"StatsAPI.predict","text":"yh = predict(ar::TransferFunction, y)\n\nPredict AR model\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict-Tuple{TransferFunction, InputOutputData}","page":"API","title":"StatsAPI.predict","text":"predict(ARX::TransferFunction, d::InputOutputData)\n\nOne step ahead prediction for an ARX process.  The length of the returned prediction is length(d) - max(na, nb)\n\nExample:\n\njulia> predict(tf(1, [1, -1], 1), iddata(1:10, 1:10))\n9-element Vector{Int64}:\n  2\n  4\n  6\n  8\n 10\n 12\n 14\n 16\n 18\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.residuals-Tuple{TransferFunction, InputOutputData}","page":"API","title":"StatsAPI.residuals","text":"residuals(ARX::TransferFunction, d::InputOutputData)\n\nCalculates the residuals v = Ay - Bu of an ARX process and InputOutputData d. The length of the returned residuals is length(d) - max(na, nb)\n\nExample:\n\njulia> ARX = tf(1, [1, -1], 1)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Int64}}\n  1\n-----\nz - 1\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> u = 1:5\n1:5\n\njulia> y = lsim(ARX, u, 1:5)[1][:]\n5-element Vector{Float64}:\n  0.0\n  1.0\n  3.0\n  6.0\n 10.0\n\njulia> d = iddata(y, u)\nInputOutput data of length 5 with 1 outputs and 1 inputs\n\njulia> residuals(ARX, d)\n4-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n 0.0\n\n\n\n\n\n","category":"method"},{"location":"api/","page":"API","title":"API","text":"DelimitedFiles.writedlm\nControlSystemsBase.c2d","category":"page"},{"location":"api/#DelimitedFiles.writedlm","page":"API","title":"DelimitedFiles.writedlm","text":"DelimitedFiles.writedlm(io::IO, d::AbstractIdData, args...; kwargs...)\n\nWrite identification data to disk.\n\n\n\n\n\n","category":"function"},{"location":"api/#ControlSystemsBase.c2d","page":"API","title":"ControlSystemsBase.c2d","text":"c2d(w::AbstractVector{<:Real}, Ts; w_prewarp = 0)\nc2d(frd::FRD, Ts; w_prewarp = 0)\n\nTransform continuous-time frequency vector w or frequency-response data frd from continuous to discrete time using a bilinear (Tustin) transform. This is useful in cases where a frequency response is obtained through frequency-response analysis, and the function subspaceid is to be used.\n\n\n\n\n\n","category":"function"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"using ControlSystemIdentification\nusing LeastSquaresOptim","category":"page"},{"location":"nonlinear/#Identification-of-nonlinear-models","page":"Nonlinear identification","title":"Identification of nonlinear models","text":"","category":"section"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"This package supports two forms of nonlinear system identification.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"Parameter estimation in a known model structure (linear or nonlinear) x = f(x u p) where p is a vector of parameters to be estimated.\nEstimation of Hammerstein-Wiener models, i.e., linear systems with static nonlinear functions on the input and/or output.","category":"page"},{"location":"nonlinear/#Parameter-estimation-in-a-known-model-structure","page":"Nonlinear identification","title":"Parameter estimation in a known model structure","text":"","category":"section"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"Parameter estimation in differential equations can be performed by forming a one-step ahead predictor of the output, and minimizing the prediction error. This procedure is packaged in the function nonlinear_pem which is available as a package extension, available if the user manually installs and loads LeastSquaresOptim.jl.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"The procedure to use this function is as follows","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"The dynamics is specified on the form x_k+1 = f(x_k u_k p t) or x = f(x u p t) where x is the state, u the input,  p is a vector of parameters to be estimated and t is time.\nIf the dynamics is in continuous time (a differential equation or differential-algebraic equation), use the package SeeToDee.jl to discretize it. If the dynamics is already in discrete time, skip this step.\nDefine the measurement function y = h(x u p t) that maps the state and input to the measured output.\nSpecify covariance properties of the dynamics noise and measurement noise, similar to how one would do when building a Kalman filter for a linear system.\nPerform the estimation using nonlinear_pem.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"Internally, nonlinear_pem constructs an Unscented Kalman filter (UKF) from the package LowLevelParticleFilters.jl in order to perform state estimation along the provided data trajectory. An optimization problem is then solved in order to find the parameters (and optionally initial condition) that minimizes the prediction errors. This procedure is somewhat different from simply finding the parameters that make a pure simulation of the system match the data, notably, the prediction-error approach can usually handle very poor initial guesses, unstable systems and even chaotic systems. To learn more about the prediction-error method, see the tutorial Properties of the Prediction-Error Method.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"ControlSystemIdentification.nonlinear_pem","category":"page"},{"location":"nonlinear/#ControlSystemIdentification.nonlinear_pem","page":"Nonlinear identification","title":"ControlSystemIdentification.nonlinear_pem","text":"nonlinear_pem(\n    d::IdData,\n    discrete_dynamics,\n    measurement,\n    p0,\n    x0,\n    R1,\n    R2,\n    nu;\n    optimizer = LevenbergMarquardt(),\n    λ = 1.0,\n    optimize_x0 = true,\n    kwargs...,\n)\n\nNonlinear Prediction-Error Method (PEM).\n\nThis method attempts to find the optimal vector of parameters, p, and the initial condition x_0, that minimizes the sum of squared one-step prediction errors. The prediction is performed using an Unscented Kalman Filter (UKF) and the optimization is performed using a Gauss-Newton method. \n\ninfo: Requires LeastSquaresOptim.jl\nThis function is available only if LeastSquaresOptim.jl is manually installed and loaded by the user.\n\nArguments:\n\nd: Identification data\ndiscrete_dynamics: A dynamics function (xₖ, uₖ, p, t) -> x(k+1) that takes the current state x, input u, parameters p, and time t and returns the next state x(k+1).\nmeasurement: The measurement / output function of the nonlinear system (xₖ, uₖ, p, t) -> yₖ\np0: The initial guess for the parameter vector\nx0: The initial guess for the initial condition\nR1: Dynamics noise covariance matrix (increasing this makes the algorithm trust the model less)\nR2: Measurement noise covariance matrix (increasing this makes the algorithm trust the measurements less)\nnu: Number of inputs to the system\noptimizer: Any optimizer from LeastSquaresOptim\nλ: A weighting factor to minimize dot(e, λ, e). A commonly used metric is λ = Diagonal(1 ./ (mag.^2)), where mag is a vector of the \"typical magnitude\" of each output. Internally, the square root of W = sqrt(λ) is calculated so that the residuals stored in res are W*e.\noptimize_x0: Whether to optimize the initial condition x0 or not. If false, the initial condition is fixed to the value of x0 and the optimization is performed only on the parameters p.\n\nThe inner optimizer accepts a number of keyword arguments:\n\nlower: Lower bounds for the parameters\nupper: Upper bounds for the parameters\nx_tol = 1e-8\nf_tol = 1e-8\ng_tol = 1e-8\niterations = 1_000\nΔ = 10.0\nstore_trace = false\n\nSee Identification of nonlinear models for more details.\n\nwarning: Experimental\nThis function is considered experimental and may change in the future without respecting semantic versioning. This implementation also lacks a number of features associated with good nonlinear PEM implementations, such as regularization and support for multiple datasets.\n\n\n\n\n\n","category":"function"},{"location":"nonlinear/#Example:-Quad-tank","page":"Nonlinear identification","title":"Example: Quad tank","text":"","category":"section"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"This example considers a quadruple tank, where two upper tanks feed liquid into two lower tanks, depicted in the schematics below. The quad-tank process is a well-studied example in many multivariable control courses, this particular instance of the process is borrowed from the Lund University introductory course on automatic control.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"(Image: process)","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"The process has a cross coupling between the tanks, governed by a parameters gamma_i: The flows from the pumps are divided according to the two parameters γ_1  γ_2  0 1. The flow to tank 1 is γ_1 k_1u_1 and the flow to tank 4 is (1 - γ_1 )k_1u_1. Tanks 2 and 3 behave symmetrically.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"The dynamics are given by","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"beginaligned\ndoth_1 = dfrac-a_1A_1   sqrt2g h_1 + dfraca_3A_1 sqrt2g h_3 +     dfracγ_1 k_1A_1   u_1 \ndoth_2 = dfrac-a_2A_2   sqrt2g h_2 + dfraca_4A_2 sqrt2g h_4 +     dfracγ_2 k_2A_2   u_2 \ndoth_3 = dfrac-a_3A_3 sqrt2g h_3                         + dfrac(1-γ_2) k_2A_3   u_2 \ndoth_4 = dfrac-a_4A_4 sqrt2g h_4                          + dfrac(1-γ_1) k_1A_4   u_1\nendaligned","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"where h_i are the tank levels and a_i A_i are the cross-sectional areas of outlets and tanks respectively.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"We start by defining the dynamics in continuous time, and discretize them using the integrator SeeToDee.Rk4 with a sample time of T_s = 1s.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"using StaticArrays, SeeToDee\n\nfunction quadtank(h, u, p, t)\n    k1, k2, g = p[1], p[2], 9.81\n    A1 = A3 = A2 = A4 = p[3]\n    a1 = a3 = a2 = a4 = 0.03\n    γ1 = γ2 = p[4]\n\n    ssqrt(x) = √(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0\n\n    SA[\n        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     γ1*k1/A1 * u[1]\n        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     γ2*k2/A2 * u[2]\n        -a3/A3*ssqrt(2g*h[3])                          + (1-γ2)*k2/A3 * u[2]\n        -a4/A4*ssqrt(2g*h[4])                          + (1-γ1)*k1/A4 * u[1]\n    ]\nend\nmeasurement(x,u,p,t) = SA[x[1], x[2]]\n\nTs = 1.0\ndiscrete_dynamics = SeeToDee.Rk4(quadtank, Ts, supersample=2)","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"The output from this system is the water level in the first two tanks, i.e., y = x_1 x_2.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"We also specify the number of state variables, outputs and inputs as well as a vector of \"true\" parameters, the ones we will try to estimate.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"nx = 4\nny = 2\nnu = 2\np_true = [1.6, 1.6, 4.9, 0.2]","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"We then simulate some data from the system to use for identification:","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"using ControlSystemIdentification, ControlSystemsBase\nusing ControlSystemsBase.DemoSystems: resonant\nusing LowLevelParticleFilters\nusing LeastSquaresOptim\nusing Random, Plots, LinearAlgebra\n\n# Generate some data from the system\nRandom.seed!(1)\nTperiod = 200\nt = 0:Ts:1000\nu1 = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* (t ./ 40).^2)) .+ 0.25)\nu2 = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* (t ./ 40).^2 .+ pi/2)) .+ 0.25)\nu  = vcat.(u1,u2)\nu = [u; 0 .* u[1:100]]\nx0 = [2.5, 1.5, 3.2, 2.8]\nx = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u, p_true)[1:end-1]\ny = measurement.(x, u, 0, 0)\ny = [y .+ 0.5randn(ny) for y in y] # Add some measurement noise\nY = reduce(hcat, y) # Go from vector of vectors to a matrix\nU = reduce(hcat, u) # Go from vector of vectors to a matrix\nplot(\n    plot(reduce(hcat, x)', title=\"States\", lab=[\"h1\" \"h2\" \"h3\" \"h4\"]),\n    plot(U', title=\"Inputs\", lab=[\"u1\" \"u2\"]),\n    plot(Y', title=\"Outputs\", lab=[\"y1\" \"y2\"]),\n)","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"We package the experimental data into an iddata object as usual. Finally, we specify the covariance matrices for the dynamics noise and measurement noise as well as a guess for the initial condition. Since we can measure the level in the first two tanks, we use the true initial condition for those tanks, but we pretend that we are quite off when guessing the initial condition for the last two tanks. ","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"Choosing the covariance matrices can be non-trivial, see the blog post How to tune a Kalman filter for some background. Here, we pick some value for R_1 that seems reasonable, and pick a deliberately large value for R_2. Choosing a large covariance of the measurement noise will lead to the state estimator trusting the measurements less, which in turns leads to a smaller feedback correction. This will make the algorithm favor a model that is good at simulation, rather than focusing exclusively on one-step prediction.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"Finally, we call the function nonlinear_pem to perform the estimation.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"d = iddata(Y, U, Ts)\nx0_guess = [2.5, 1.5, 1, 2] # Guess for the initial condition\np_guess = [1.4, 1.4, 5.1, 0.25] # Initial guess for the parameters\n\nR1 = Diagonal([0.1, 0.1, 0.1, 0.1])\nR2 = 100*Diagonal(0.5^2 * ones(ny))\n\nmodel = ControlSystemIdentification.nonlinear_pem(d, discrete_dynamics, measurement, p_guess, x0_guess, R1, R2, nu)","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"We can then test how the model performs on the data, and compare with the model corresponding to our initial guess","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"simplot(model, d, layout=2)\n\nx_guess = LowLevelParticleFilters.rollout(discrete_dynamics, x0_guess, u, p_guess)[1:end-1]\ny_guess = measurement.(x_guess, u, 0, 0)\nplot!(reduce(hcat, y_guess)', lab=\"Initial guess\")","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"We can also perform a residual analysis to see if the model is able to capture the dynamics of the system","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"residualplot(model, d)","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"since we are using simulated data here, the residuals are white and there's nothing to worry about. In practice, one should always inspect the residuals to see if there are any systematic errors in the model.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"Internally, the returned model object contains the estimated parameters, let's see if they are any good","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"[p_true p_guess model.p]","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"hopefully, the estimated parameters are close to the true ones.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"To customize the implementation of the nonlinear prediction-error method, see a lower-level interface being used in the tutorial in the documentation of LowLevelParticleFilters.jl which also provides the UKF.","category":"page"},{"location":"nonlinear/#Hammerstein-Wiener-estimation","page":"Nonlinear identification","title":"Hammerstein-Wiener estimation","text":"","category":"section"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"This package provides elementary identification of nonlinear systems on Hammerstein-Wiener form, i.e., systems with a static input nonlinearity and a static output nonlinearity with a linear system in-between, where the nonlinearities are known. The only aspect of the nonlinearities that are optionally estimated are parameters. To formalize this, the estimation method newpem allows for estimation of a model of the form","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"beginaligned\nx^+ = Ax + B u_nl \ny = Cx + D u_nl   \nu_nl = g_i(u p)  \ny_nl = g_o(y p)\nendaligned","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"   ┌─────┐   ┌─────┐   ┌─────┐\n u │     │uₙₗ│     │ y │     │ yₙₗ\n──►│  gᵢ ├──►│  P  ├──►│  gₒ ├─►\n   │     │   │     │   │     │\n   └─────┘   └─────┘   └─────┘","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"where g_i and g_o are static, nonlinear functions that may depend on some parameter vector p which is optimized together with the matrices ABCD. The procedure to estimate such a model is detailed in the docstring for newpem.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"The result of this estimation is the linear system without the nonlinearities applied, those must be handled manually by the user.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"The default optimizer BFGS may struggle with problems including nonlinearities. If you do not get good results, try a different optimizer, e.g., optimizer = Optim.NelderMead().","category":"page"},{"location":"nonlinear/#Example-with-simulated-data:","page":"Nonlinear identification","title":"Example with simulated data:","text":"","category":"section"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"The example below identifies a model of a resonant system where the sign of the output is unknown, i.e., the output nonlinearity is given by y_nl = y. To make the example a bit more realistic, we also simulate colored measurement and input noise, yn and un. For an example with real data, see Hammerstein-Wiener estimation of nonlinear belt-drive system.","category":"page"},{"location":"nonlinear/","page":"Nonlinear identification","title":"Nonlinear identification","text":"using ControlSystemIdentification, ControlSystemsBase\nusing ControlSystemsBase.DemoSystems: resonant\nusing Random, Plots\n\n# Generate some data from the system\nRandom.seed!(1)\nT = 200\nsys = c2d(resonant(ω0 = 0.1) * tf(1, [0.1, 1]), 1)# generate_system(nx, nu, ny)\nnx = sys.nx\nnu = 1\nny = 1\nx0 = zeros(nx)\nsim(sys, u, x0 = x0) = lsim(sys, u, 1:T, x0 = x0)[1]\nsysn = c2d(resonant(ω0 = 1) * tf(1, [0.1, 1]), 1)\n\nσu = 1e-2 # Input noise standard deviation\nσy = 1e-3 # Output noise standard deviation\n\nu  = randn(nu, T)\nun = u + sim(sysn, σu * randn(size(u)), 0 * x0)\ny  = sim(sys, un, x0)\nyn = y + sim(sysn, σy * randn(size(u)), 0 * x0)\n\n# Nonlinear output transformation\nynn = abs.(yn)\nd  = iddata(ynn, un, 1)\noutput_nonlinearity = (y, p) -> y .= abs.(y)\n\n# Estimate 10 models with different random initialization and pick the best one\n# If results are poor, try `optimizer = Optim.NelderMead()` instead\nresults = map(1:10) do _\n    sysh, x0h, opt = newpem(d, nx; output_nonlinearity, show_trace=false, focus = :simulation)\n    (; sysh, x0h, opt)\nend;\n\n(; sysh, x0h, opt) = argmin(r->r.opt.minimum, results) # Find the model with the smallest cost\n\nyh = simulate(sysh, d, x0h)\noutput_nonlinearity(yh, nothing) # We need to manually apply the output nonlinearity to the prediction\nplot(d.t, [abs.(y); u]', lab=[\"True nonlinear output\" \"Input\"], seriestype = [:line :steps], layout=(2,1), xlabel=\"Time\")\nscatter!(d.t, ynn', lab=\"Measured nonlinear output\", sp=1)\nplot!(d.t, yh', lab=\"Simulation\", sp=1, l=:dash)","category":"page"},{"location":"ss/#Statespace-model-estimation","page":"State-space estimation","title":"Statespace model estimation","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"This page documents the facilities available for estimating linear statespace models with inputs on the form","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"beginaligned\nx^+ = Ax + Bu + Ke\ny = Cx + Du + e\nendaligned","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"This package estimates models in discrete time, but they may be converted to continuous-time models using the function d2c from ControlSystemsBase.jl.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"There exist several methods for identification of statespace models, subspaceid, n4sid, newpem and era. subspaceid is the most comprehensive algorithm for subspace-based identification whereas n4sid is an older implementation. newpem solves the prediction-error problem using an iterative optimization method (from Optim.jl) and ins generally slightly more accurate but also more computationally expensive. If unsure which method to use, try subspaceid first (unless the data comes from closed-loop operation, use newpem in this case).","category":"page"},{"location":"ss/#Subspace-based-identification-using-n4sid-and-subspaceid","page":"State-space estimation","title":"Subspace-based identification using n4sid and subspaceid","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"In this example we will estimate a statespace model using the subspaceid method. This function returns an object of type N4SIDStateSpace where the model is accessed as sys.sys.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"using ControlSystemIdentification, ControlSystemsBase, Plots\ngr(fmt=:png) # hide\nTs = 0.1\nG  = c2d(DemoSystems.resonant(), Ts)\nu  = randn(1,1000)\ny  = lsim(G,u).y\ny .+= 0.01 .* randn.() # add measurement noise\nd  = iddata(y,u,Ts)\nsys = subspaceid(d, :auto; verbose=false, zeroD=true)\n\n# or use a robust version of svd if y has outliers or missing values\n# using TotalLeastSquares\n# sys = n4sid(d, :auto; verbose=false, svd=x->rpca(x)[3])\nbodeplot([G, sys.sys], lab=[\"True\" \"\" \"subspace\" \"\"])","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"N4SIDStateSpace is a subtype of AbstractPredictionStateSpace, a statespace object that contains an observer gain matrix sys.K (Kalman filter) as well as estimated covariance matrices etc.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"Using the function n4sid instead, we have","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"sys2 = n4sid(d, :auto; verbose=false, zeroD=true)\nbodeplot!(sys2.sys, lab=[\"n4sid\" \"\"])","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"subspaceid allows you to choose the weighting between :MOESP, :CVA, :N4SID, :IVM and is generally preferred over n4sid.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"Both functions allow you to choose which functions are used for least-squares estimates and computing the SVD, allowing e.g., robust estimators for resistance against outliers etc.","category":"page"},{"location":"ss/#Tuning-the-model-fit","page":"State-space estimation","title":"Tuning the model fit","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"The subspace-based estimation algorithms have a number of parameters that can be tuned if the initial model fit is not satisfactory.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"focus determines the focus of the model fit. The default is :prediction which minimizes the prediction error. If this choice produces an unstable model for a stable system, or the simmulation performance is poor, focus = :simulation may be a better choice.\nThere are several horizon parameters that can be tuned. The keyword argument r selects the prediction horizon, this has to be greater than the model order, with the default being nx + 10. s1 and s2 control the past horizons for the output and input, respectively. The default is s1 = s2 = r. Past horizons can only be tuned for subspaceid.\n(Advanced) The method used to compute the svd as well as performing least-squares fitting can be changed using the keywords svd, Aestimator, Bestimator.\nzeroD allows you to force the estimated D matrix to be zero (a strictly proper model).\nIt is possible to select the weight type W, choose between :MOESP, :CVA, :N4SID, :IVM. The default is :MOESP.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"See the docstrings of subspaceid and n4sid for additional arguments and more details.","category":"page"},{"location":"ss/#ERA-and-OKID","page":"State-space estimation","title":"ERA and OKID","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"The \"Eigenvalue realization algorithm\" and \"Observer Kalman identification\" algorithms are available as era and okid. If era is called with a data object, okid is automatically used internally to produce the Markov parameters to the ERA algorithm.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"sys3 = era(d, 2) # era has a lot of parameters that may require tuning\nbodeplot!(sys3, lab=[\"ERA\" \"\"])","category":"page"},{"location":"ss/#Using-multiple-datasets","page":"State-space estimation","title":"Using multiple datasets","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"ERA/OKID supports the use of multiple datasets to improve the estimation accuracy. Below, we show how to perform this manually","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"using ControlSystemIdentification, ControlSystemsBase, Plots, Statistics\ngr(fmt=:png) # hide\nTs = 0.1\nG = c2d(tf(1, [1,1,1]), Ts) # True system\n\n# Create several \"experiments\"\nds = map(1:5) do i\n    u = randn(1, 1000)\n    y, t, x = lsim(G, u)\n    yn = y + 0.2randn(size(y))\n    iddata(yn, u, Ts)\nend\n\nYs = okid.(ds, 2, round(Int, 10/Ts), smooth=true, λ=1)    # Estimate impulse response for each experiment\nY = mean(Ys)                            # Average all impulse responses\n\nimp = impulse(G, 10)\nf1 = plot(imp, lab=\"True\", l=5)\nplot!(imp.t, vec.(Ys), lab=\"Individual estimates\", title=\"Impulse-response estimates\")\nplot!(imp.t, vec(Y), l=(3, :black), lab=\"Mean\")\n\nmodels = era.(Ys, Ts, 2, 50, 50)    # estimate models based on individual experiments\nmeanmodel = era(Y, Ts, 2, 50, 50)   # estimate model based on mean impulse response\n\nf2 = bodeplot([G, meanmodel], lab=[\"True\" \"\" \"Combined estimate\" \"\"], l=2)\nbodeplot!(models, lab=\"Individual estimates\", c=:black, alpha=0.5, legend=:bottomleft)\n\nplot(f1, f2)","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"The procedure shown above is equivalent to calling era directly with a vector of data sets, in which case the averaging of the impulse responses is done internally.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"era(ds, 2, 50, 50, round(Int, 10/Ts), p=1, λ=1, smooth=true) # Should be identical to meanmodel above","category":"page"},{"location":"ss/#Prediction-error-method-(PEM)","page":"State-space estimation","title":"Prediction-error method (PEM)","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"note: Note\nThe old function pem is \"soft deprecated\" in favor of newpem which is more general and much more performant.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"The prediction-error method is a simple but powerful algorithm for identification of discrete-time LTI systems on state-space form:","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"beginaligned\nx = Ax + Bu + Ke \ny  = Cx + Du + e\nendaligned","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"The user can choose to minimize either prediction errors or simulation errors, with arbitrary metrics, i.e., not limited to squared errors.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"The result of the identification with newpem is a custom type with extra fields for the identified Kalman gain and noise covariance matrices.","category":"page"},{"location":"ss/#Gray-box-identification","page":"State-space estimation","title":"Gray-box identification","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"For estimation of linear or nonlinear models with fixed structure, see ControlSystemIdentification.nonlinear_pem.","category":"page"},{"location":"ss/#Usage-example","page":"State-space estimation","title":"Usage example","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"Below, we generate a system and simulate it forward in time. We then try to estimate a model based on the input and output sequences using the function newpem.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"using ControlSystemIdentification, ControlSystemsBase, Random, LinearAlgebra\nusing ControlSystemIdentification: newpem\nsys = c2d(tf(1, [1, 0.5, 1]) * tf(1, [1, 1]), 0.1)\n\nRandom.seed!(1)\nT   = 1000                      # Number of time steps\nnx  = 3                         # Number of poles in the true system\nnu  = 1                         # Number of inputs\nx0  = randn(nx)                 # Initial state\nsim(sys,u,x0=x0) = lsim(ss(sys), u, x0=x0).y # Helper function\nu   = randn(nu,T)               # Generate random input\ny   = sim(sys, u, x0)           # Simulate system\ny .+= 0.01 .* randn.()          # Add some measurement noise\nd   = iddata(y,u,0.1)\n\nsysh,opt = newpem(d, nx, focus=:prediction) # Estimate model\n\nyh = predict(sysh, d) # Predict using estimated model\npredplot(sysh, d)     # Plot prediction and true output","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"See the example notebooks for more plots as well as several examples in the example section of this documentation.","category":"page"},{"location":"ss/#Arguments","page":"State-space estimation","title":"Arguments","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"The algorithm has several options:","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"The optimization is by default started with an initial guess provided by subspaceid, but this can be overridden by providing an initial guess to newpem using the keyword argument sys0.\nfocus determines the focus of the model fit. The default is :prediction which minimizes the prediction error. If this choice produces an unstable model for a stable system, or the simmulation performance is poor, focus = :simulation may be a better choice.\nA regularizer may be provided using the keyword argument regularizer.\nA stable model may be enforced using stable = true.\nThe D matrix may be forced to be zero using zeroD = true.\nA trade-off between prediction and simulation performance can be achieved by optimizing the h-step prediction error. The default is h=1 which corresponds to the standard prediction error. This can be changed using the keyword argument h. A large value of h will make the optimization problem computationally expensive to solve.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"See the docstring of newpem for additional arguments and more details.","category":"page"},{"location":"ss/#Internals","page":"State-space estimation","title":"Internals","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"Internally, Optim.jl is used to optimize the system parameters, using automatic differentiation to calculate gradients (and Hessians where applicable). Optim solver options can be controlled by passing keyword arguments to newpem, and by passing a manually constructed solver object. The default solver is BFGS()","category":"page"},{"location":"ss/#Filtering,-prediction-and-simulation","page":"State-space estimation","title":"Filtering, prediction and simulation","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"When you estimate models, you can sometimes select the \"focus\" of the estimation, to either focus on :prediciton performance or :simulation performance. Simulation tends to require accurate low-frequency properties, especially for integrating systems, whereas prediction favors an accurate model for higher frequencies. If there are significant input disturbances affecting the system, or if the system is unstable, prediction focus is generally preferred.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"When you validate the estimated models, you can simulate them using lsim from ControlSystemsBase.jl or using simulate. You may also convert the model to a KalmanFilter from LowLevelParticleFilters.jl by calling KalmanFilter(sys), after which you can perform filtering and smoothing etc. with the utilities provided for a KalmanFilter.","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"Furthermore, we have the utility functions below","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"predict(sys, d, x0=zeros; h=1): Form predictions using estimated sys, this essentially runs a stationary Kalman filter. h denotes the prediction horizon.\nsimulate(sys, u, x0=zeros): Simulate the system using input u. The noise model and Kalman gain does not have any influence on the simulated output.\nobserver_predictor: Extract the predictor model from the estimated system (ss(A-KC,[B K],C,D)).\nobserver_controller\nprediction_error\nprediction_error_filter\npredictiondata\nnoise_model","category":"page"},{"location":"ss/#Code-generation","page":"State-space estimation","title":"Code generation","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"To generate C-code for, e.g., simulating a system, see SymbolicControlSystems.jl.","category":"page"},{"location":"ss/#Statespace-API","page":"State-space estimation","title":"Statespace API","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"ControlSystemIdentification.subspaceid\nControlSystemIdentification.n4sid\nControlSystemIdentification.newpem\nControlSystemIdentification.era\nControlSystemIdentification.okid\nControlSystemIdentification.predictiondata\nControlSystemIdentification.observer_predictor\nControlSystemIdentification.observer_controller\nControlSystemIdentification.prediction_error\nControlSystemIdentification.prediction_error_filter\nControlSystemIdentification.noise_model","category":"page"},{"location":"ss/#ControlSystemIdentification.subspaceid","page":"State-space estimation","title":"ControlSystemIdentification.subspaceid","text":"subspaceid(\n    data::InputOutputData,\n    nx = :auto;\n    verbose = false,\n    r = nx === :auto ? min(length(data) ÷ 20, 20) : nx + 10, # the maximal prediction horizon used\n    s1 = r, # number of past outputs\n    s2 = r, # number of past inputs\n    W = :MOESP,\n    zeroD = false,\n    stable = true, \n    focus = :prediction,\n    svd::F1 = svd!,\n    scaleU = true,\n    Aestimator::F2 = \\,\n    Bestimator::F3 = \\,\n    weights = nothing,\n)\n\nEstimate a state-space model using subspace-based identification. Several different subspace-based algorithms are available, and can be chosen using the W keyword. Options are :MOESP, :CVA, :N4SID, :IVM.\n\nRef: Ljung, Theory for the user.\n\nResistance against outliers can be improved by supplying a custom factorization algorithm and replacing the internal least-squares estimators. See the documentation for the keyword arguments svd, Aestimator, and Bestimator below.\n\nThe returned model is of type N4SIDStateSpace and contains the field sys with the system model, as well as covariance matrices for a Kalman filter.\n\nArguments:\n\ndata: Identification data iddata\nnx: Rank of the model (model order)\nverbose: Print stuff?\nr: Prediction horizon. The model may perform better on simulation if this is made longer, at the expense of more computation time.\ns1: past horizon of outputs\ns2: past horizon of inputs\nW: Weight type, choose between :MOESP, :CVA, :N4SID, :IVM\nzeroD: Force the D matrix to be zero.\nstable: Stabilize unstable system using eigenvalue reflection.\nfocus: :prediction or simulation\nsvd: The function to use for svd. For resistance against outliers, consider using TotalLeastSquares.rpca to preprocess the data matrix before applying svd, like svd = A->svd!(rpca(A)[1]).\nscaleU: Rescale the input channels to have the same energy.\nAestimator: Estimator function used to estimate A,C. The default is `, i.e., least squares, but robust estimators, such asirls, flts, rtls` from TotalLeastSquares.jl, can be used to gain resistance against outliers.\nBestimator: Estimator function used to estimate B,D. Weighted estimation can be eachieved by passing wls from TotalLeastSquares.jl together with the weights keyword argument.\nweights: A vector of weights can be provided if the Bestimator is wls. \n\nExtended help\n\nA more accurate prediciton model can sometimes be obtained using newpem, which is also unbiased for closed-loop data (subspaceid is biased for closed-loop data, see example in the docs). The prediction-error method is iterative and generally more expensive than subspaceid, and uses this function (by default) to form the initial guess for the optimization.\n\n\n\n\n\nmodel, x0 = subspaceid(frd::FRD, Ts, args...; estimate_x0 = false, bilinear_transform = false, kwargs...)\n\nIf a frequency-reponse data object is supplied\n\nThe FRD will be automatically converted to an InputOutputFreqData\nestimate_x0 is by default set to 0.\nbilinear_transform transform the frequency vector to discrete time, see note below.\n\nNote: if the frequency-response data comes from a frequency-response analysis, a bilinear transform of the data is required before estimation. This transform will be applied if bilinear_transform = true.\n\n\n\n\n\nmodel, x0 = subspaceid(data::InputOutputFreqData,\n    Ts = data.Ts,\n    nx = :auto;\n    cont = false,\n    verbose = false,\n    r = nx === :auto ? min(length(data) ÷ 20, 20) : 2nx, # Internal model order\n    zeroD = false,\n    estimate_x0 = true,\n    stable = true, \n    svd = svd!,\n    Aestimator = \\,\n    Bestimator = \\,\n    weights = nothing\n)\n\nEstimate a state-space model using subspace-based identification in the frequency domain.\n\nIf results are poor, try modifying r, in particular if the amount of data is low.\n\nSee the docs for an example.\n\nArguments:\n\ndata: A frequency-domain identification data object.\nTs: Sample time at which the data was collected\nnx: Desired model order, an interer or :auto.\ncont: Return a continuous-time model? A bilinear transformation is used to convert the estimated discrete-time model, see function d2c.\nverbose: Print stuff?\nr: Internal model order, must be ≥ nx.\nzeroD: Force the D matrix to be zero.\nestimate_x0: Esimation of extra parameters to account for initial conditions. This may be required if the data comes from the fft of time-domain data, but may not be required if the data is collected using frequency-response analysis with exactly periodic input and proper handling of transients.\nstable: For the model to be stable (uses schur_stab).\nsvd: The svd function to use.\nAestimator: The estimator of the A matrix (and initial C-matrix).\nBestimator: The estimator of B/D and C/D matrices.\nweights: An optional vector of frequency weights of the same length as the number of frequencies in `data.\n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemIdentification.n4sid","page":"State-space estimation","title":"ControlSystemIdentification.n4sid","text":"res = n4sid(data, r=:auto; verbose=false)\n\nEstimate a statespace model using the n4sid method. Returns an object of type N4SIDStateSpace where the model is accessed as res.sys.\n\nImplements the simplified algorithm (alg 2) from \"N4SID: Subspace Algorithms for the Identification of Combined Deterministic Stochastic Systems\" PETER VAN OVERSCHEE and BART DE MOOR\n\nThe frequency weighting is borrowing ideas from \"Frequency Weighted Subspace Based System Identification in the Frequency Domain\", Tomas McKelvey 1996. In particular, we apply the output frequency weight matrix (Fy) as it appears in eqs. (16)-(18).\n\nArguments:\n\ndata: Identification data data = iddata(y,u)\nr: Rank of the model (model order)\nverbose: Print stuff?\nWf: A frequency-domain model of measurement disturbances. To focus the attention of the model on a narrow frequency band, try something like Wf = Bandstop(lower, upper, fs=1/Ts) to indicate that there are disturbances outside this band.\ni: Algorithm parameter, generally no need to tune this\nγ: Set this to a value between (0,1) to stabilize unstable models such that the largest eigenvalue has magnitude γ.\nzeroD: defaults to false\n\nSee also the newer implementation subspaceid which allows you to choose between different weightings (n4sid being one of them). A more accurate prediciton model can sometimes be obtained using newpem, which is also unbiased for closed-loop data.\n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemIdentification.newpem","page":"State-space estimation","title":"ControlSystemIdentification.newpem","text":"sys, x0, res = newpem(\n    d,\n    nx;\n    zeroD  = true,\n    focus  = :prediction,\n    stable = true,\n    sys0   = subspaceid(d, nx; zeroD, focus, stable),\n    metric = abs2,\n    regularizer = (p, P) -> 0,\n    output_nonlinearity = nothing,\n    input_nonlinearity = nothing,\n    nlp = nothing,\n    optimizer = BFGS(\n        linesearch = LineSearches.BackTracking(),\n    ),\n    store_trace = true,\n    show_trace  = true,\n    show_every  = 50,\n    iterations  = 10000,\n    time_limit  = 100,\n    x_tol       = 0,\n    f_abstol    = 0,\n    g_tol       = 1e-12,\n    f_calls_limit = 0,\n    g_calls_limit = 0,\n    allow_f_increases = false,\n)\n\nA new implementation of the prediction-error method (PEM). Note that this is an experimental implementation and subject to breaking changes not respecting semver.\n\nThe prediction-error method is an iterative, gradient-based optimization problem, as such, it can be extra sensitive to signal scaling, and it's recommended to perform scaling to d before estimation, e.g., by pre and post-multiplying with diagonal matrices d̃ = Dy*d*Du, and apply the inverse scaling to the resulting system. In this case, we have\n\nD_y y = G D_u u  y = D_y^-1 G D_u u\n\nhence G = Dy \\ G̃ * Du where $ G̃ $ is the plant estimated for the scaled iddata. Example:\n\nDy = Diagonal(1 ./ vec(std(d.y, dims=2))) # Normalize variance\nDu = Diagonal(1 ./ vec(std(d.u, dims=2))) # Normalize variance\nd̃ = Dy * d * Du\n\nIf a manually provided initial guess sys0, this must also be scaled appropriately.\n\nArguments:\n\nd: iddata\nnx: Model order\nzeroD: Force zero D matrix\nstable if true, stability of the estimated system will be enforced by eigenvalue reflection using schur_stab with ϵ=1/100 (default). If stable is a real value, the value is used instead of the default ϵ.\nsys0: Initial guess, if non provided, subspaceid is used as initial guess.\nfocus: prediction or :simulation. If :simulation, the K matrix will be zero.\noptimizer: One of Optim's optimizers\nmetric: The metric used to measure residuals. Try, e.g., abs for better resistance to outliers.\n\nThe rest of the arguments are related to Optim.Options.\n\nregularizer: A function of the parameter vector and the corresponding PredictionStateSpace/StateSpace system that can be used to regularize the estimate.\noutput_nonlinearity: A function of (y::Vector, p) that operates on the output signal at a single time point, yₜ, and modifies it in-place. See below for details. p is a vector of estimated parameters that can be optimized.\ninput_nonlinearity: A function of (u::Matrix, p) that operates on the entire input signal u at once and modifies it in-place. See below for details. p is a vector of estimated parameters that is shared with output_nonlinearity.\nnlp: Initial guess vector for nonlinear parameters. If output_nonlinearity is provided, this can optionally be provided.\n\nNonlinear estimation\n\nNonlinear systems on Hammerstein-Wiener form, i.e., systems with a static input nonlinearity and a static output nonlinearity with a linear system inbetween, can be estimated as long as the nonlinearities are known. The procedure is\n\nIf there is a known input nonlinearity, manually apply the input nonlinearity to the input signal u before estimation, i.e., use the nonlinearly transformed input in the iddata object d. If the input nonlinearity has unknown parameters, provide the input nonlinearity as a function using the keyword argument input_nonlinearity to newpem. This function is expected to operate on the entire (matrix) input signal u and modify it in-place.\nIf the output nonlinearity is invertible, apply the inverse to the output signal y before estimation similar to above.\nIf the output nonlinearity is not invertible, provide the nonlinear output transformation as a function using the keyword argument output_nonlinearity to newpem. This function is expected to operate on the (vector) output signal y and modify it in-place. Example:\n\nfunction output_nonlinearity(y, p)\n    y[1] = y[1] + p[1]*y[1]^2       # Note how the incoming vector is modified in-place\n    y[2] = abs(y[2])\nend\n\nPlease note, y = f(y) does not change y in-place, but creates a new vector y and assigns it to the variable y. This is not what we want here.\n\nThe second argument to input_nonlinearity and output_nonlinearity is an (optional) vector of parameters that can be optimized. To use this option, pass the keyword argument nlp to newpem with a vector of initial guesses for the nonlinear parameters. The nonlinear parameters are shared between output and input nonlinearities, i.e., these two functions will receive the same vector of parameters.\n\nThe result of this estimation is the linear system without the nonlinearities.\n\nExample\n\nThe following simulates data from a linear system and estimates a model. For an example of nonlinear identification, see the documentation.\n\nusing ControlSystemIdentification, ControlSystemsBase Plots\nG = DemoSystems.doylesat()\nT = 1000  # Number of time steps\nTs = 0.01 # Sample time\nsys = c2d(G, Ts)\nnx = sys.nx\nnu = sys.nu\nny = sys.ny\nx0 = zeros(nx) # actual initial state\nsim(sys, u, x0 = x0) = lsim(sys, u; x0)[1]\n\nσy = 1e-1 # Noise covariance\n\nu  = randn(nu, T)\ny  = sim(sys, u, x0)\nyn = y .+ σy .* randn.() # Add measurement noise\nd  = iddata(yn, u, Ts)\n\nsysh, x0h, opt = ControlSystemIdentification.newpem(d, nx, show_every=10)\n\nplot(\n    bodeplot([sys, sysh]),\n    predplot(sysh, d, x0h), # Include the estimated initial state in the prediction\n)\n\nThe returned model is of type PredictionStateSpace and contains the field sys with the system model, as well as covariance matrices and estimated Kalman gain for a Kalman filter.\n\nSee also nonlinear_pem.\n\nExtended help\n\nThis implementation uses a tridiagonal parametrization of the A-matrix that has been shown to be favourable from an optimization perspective.¹ The initial guess sys0 is automatically transformed to a special tridiagonal modal form.  [1]: Mckelvey, Tomas & Helmersson, Anders. (1997). State-space parametrizations of multivariable linear systems using tridiagonal matrix forms.\n\nThe parameter vector used in the optimization takes the following form\n\np = [trivec(A); vec(B); vec(C); vec(D); vec(K); vec(x0)]\n\nWhere ControlSystemIdentification.trivec vectorizes the -1,0,1 diagonals of A. If focus = :simulation, K is omitted, and if zeroD = true, D is omitted.\n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemIdentification.era","page":"State-space estimation","title":"ControlSystemIdentification.era","text":"era(YY::AbstractArray{<:Any, 3}, Ts, nx::Int, m::Int = 2nx, n::Int = 2nx)\n\nEigenvalue realization algorithm. The algorithm returns a statespace model.\n\nArguments:\n\nYY: Markov parameters (impulse response) size ny × nu × n_time\nTs: Sample time\nnx: Model order\nm: Number of rows in Hankel matrix\nn: Number of columns in Hankel matrix\n\n\n\n\n\nera(d::AbstractIdData, nx; m = 2nx, n = 2nx, l = 5nx, p = l, λ=0, smooth=false)\nera(ds::Vector{IdData}, nx; m = 2nx, n = 2nx, l = 5nx, p = l, λ=0, smooth=false)\n\nEigenvalue realization algorithm. Uses okid to find the Markov parameters as an initial step.\n\nThe parameter l is likely to require tuning, a reasonable starting point to choose l large enough for the impulse response to have mostly dissipated.\n\nIf a vector of datasets is provided, the Markov parameters estimated from each experiment are averaged before calling era. This allows use of data from multiple experiments to improve the model estimate.\n\nArguments:\n\nnx: Model order\nl: Number of Markov parameters to estimate.\nλ: Regularization parameter (don't overuse this, prefer to make more experiments instead)\nsmooth: If true, the regularization given by λ penalizes curvature in the estimated impulse response.\np: Optionally, delete the first p columns in the internal Hankel matrices to account for initial conditions != 0. If x0 != 0, for era, p defaults to l, while when calling okid directly, p defaults to 0.\n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemIdentification.okid","page":"State-space estimation","title":"ControlSystemIdentification.okid","text":"H = okid(d::AbstractIdData, nx, l = 5nx; p = 1, λ=0, estimator = /)\n\nObserver Kalman filter identification. Returns the Markov parameters (impulse response) H size ny × nu × (l+1).\n\nThe parameter l is likely to require tuning, a reasonable starting point to choose l large enough for the impulse response to have mostly dissipated.\n\nArguments:\n\nnx: Model order\nl: Number of Markov parameters to estimate (length of impulse response).\nλ: Regularization parameter\nsmooth: If true, the regularization given by λ penalizes curvature in the estimated impulse response. If era is to be used after okid, favor a small λ with smooth=true, but if the impulse response is to be inspected by eye, a larger smoothing can yield a visually more accurate estimate of the impulse response.\np: Optionally, delete the first p columns in the internal Hankel matrices to account for initial conditions != 0. If x0 != 0, try setting p around the same value as l.\nestimator: Function to use for estimating the Markov parameters. Defaults to / (least squares), but can also be a robust option such as TotalLeastSquares.irls / flts or TotalLeastSquares.tls for a total least-squares solutoins (errors in variables).\n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemsBase.observer_predictor","page":"State-space estimation","title":"ControlSystemsBase.observer_predictor","text":"observer_predictor(sys::N4SIDStateSpace; h=1)\n\nReturn the predictor system\n\nx = (A - KC)x + (B-KD)u + Ky \ny  = Cx + Du\n\nwith the input equation [B-KD K] * [u; y]\n\nh ≥ 1 is the prediction horizon.\n\nSee also noise_model and prediction_error_filter.\n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemsBase.observer_controller","page":"State-space estimation","title":"ControlSystemsBase.observer_controller","text":"observer_controller(sys::AbstractPredictionStateSpace, L)\n\nReturns the measurement-feedback controller that takes in y and forms the control signal u = -Lx̂. See also ff_controller. \n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemIdentification.prediction_error","page":"State-space estimation","title":"ControlSystemIdentification.prediction_error","text":"e = prediction_error(sys::AbstractStateSpace, d::AbstractIdData, args...; kwargs...)\n\nReturn the prediction errors `d.y - predict(sys, d, ...)\n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemIdentification.prediction_error_filter","page":"State-space estimation","title":"ControlSystemIdentification.prediction_error_filter","text":"prediction_error_filter(sys::AbstractPredictionStateSpace; h=1)\nprediction_error_filter(sys::AbstractStateSpace, R1, R2; h=1)\n\nReturn a filter that takes [u; y] as input and outputs the prediction error e = y - ŷ. See also innovation_form and noise_model. h ≥ 1 is the prediction horizon. See function predictiondata to generate an iddata that has [u; y] as inputs.\n\n\n\n\n\n","category":"function"},{"location":"ss/#ControlSystemIdentification.noise_model","page":"State-space estimation","title":"ControlSystemIdentification.noise_model","text":"noise_model(sys::AbstractPredictionStateSpace)\n\nReturn a model of the noise driving the system, v, in\n\nx = Ax + Bu + Kv\ny = Cx + Du + v\n\nThe model neglects u and is given by\n\nx = Ax + Kv\ny = Cx + v\n\nAlso called the \"innovation form\". This function calls ControlSystemsBase.innovation_form.\n\n\n\n\n\n","category":"function"},{"location":"ss/#Video-tutorial","page":"State-space estimation","title":"Video tutorial","text":"","category":"section"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"A video tutorial performing statespace estimation is available here:","category":"page"},{"location":"ss/","page":"State-space estimation","title":"State-space estimation","text":"<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/z8o83UORuqQ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"examples/ballandbeam/#Ball-and-beam","page":"Ball and beam","title":"Ball and beam","text":"","category":"section"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"In this example, we will estimate a model for a ball on a beam. ","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"We will get the data from STADIUS's Identification Database","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"using DelimitedFiles, Plots\nusing ControlSystemIdentification, ControlSystemsBase\n\n\n## Ball and beam\nurl = \"https://ftp.esat.kuleuven.be/pub/SISTA/data/mechanical/ballbeam.dat.gz\"\nzipfilename = \"/tmp/bb.dat.gz\"\npath = Base.download(url, zipfilename)\nrun(`gunzip -f $path`)\ndata = readdlm(path[1:end-3])\nu = data[:, 1]' # beam angle\ny = data[:, 2]' # ball position\nd = iddata(y, u, 0.1)","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"The input consists of the beam angle and the output is the position of the ball on the beam. This process is unstable (indeed, any student who has ever tried to control this process is familiar with the very recognizable sound of a nickel ball hitting the floor).","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"Before we estimate any model, we inspect the data and the coherence function","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"plot(\n    plot(d),\n    coherenceplot(d),\n)","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"The coherence is low for very low and high frequencies. Since the process is unstable, the data is collected in closed loop, and the input does not contain much DC energy. We thus expect to have difficulties recovering the DC properties of the model.","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"Since the data is collected in closed loop, we use an identification method that is unbiased in the presence of feedback. We'll go with the prediction-error method (PEM). Since the process is unstable, we tell the identification routine that we accept an unstable model by saying stable=false. If we do not do this, newpem will try to stabilize an estimated unstable model. ","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"We also split the data in half, and use the first half for estimation and the second for validation.","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"dtrain = d[1:end÷2]\ndval = d[end÷2:end]\n\n# A model of order 2-3 is reasonable, \nmodel,_ = newpem(dtrain, 3, stable=false)\n\npredplot(model, dval, h=1)\npredplot!(model, dval, h=10, ploty=false)\npredplot!(model, dval, h=20, ploty=false)","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"The figures above show the result of predicting h=1 10 20 steps into the future. Since the process is unstable, simulation is unstable and not feasible,[1] and already 20 steps prediction shows tendencies towards being unstable.","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"We can visualize the estimated models in the frequency domain as well. We show both the model estimated using PEM and a nonparametric estimate using a Fourier-based method (tfest), this method estimates a noise model as well.","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"w = exp10.(LinRange(-1.5, log10(pi/d.Ts), 200))\nbodeplot(model.sys, w, lab=\"PEM\", plotphase=false)\nplot!(tfest(d))","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"It looks like the two models disagree for low frequencies, which is expected after the discussion above.","category":"page"},{"location":"examples/ballandbeam/","page":"Ball and beam","title":"Ball and beam","text":"[1]: To learn more, see Identification of unstable systems","category":"page"},{"location":"examples/closed_loop_id/#Closed-loop-identification","page":"Identification in closed loop","title":"Closed-loop identification","text":"","category":"section"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"This example will investigate how different identification algorithms perform on closed-loop data, i.e., when the input to the system is produced by a controller using output feedback.","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"We will consider a very simple system G(z) = dfrac1z - 09 with colored output noise and various inputs formed by output feedback u = -Ly + r(t), where r will vary between the experiments.","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"It is well known that in the absence of r and with a simple regulator, identifiability is poor, indeed, if","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"y_k+1 = a y_k + b u_k quad u_k = L y_k","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"we get the closed-loop system","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"y_k+1 = (a + bL)y_k","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"where we can not distinguish a and b. The introduction of r resolves this","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"beginaligned\ny_k+1 = a y_k + b u_k \nu_k = L y_k + r \ny_k+1 = (a + bL)y_k + b r_k\nendaligned","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"The very first experiment below will illustrate the problem when there is no excitation through r.","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"We start by defining a model of the true system, a function that simulates some data and adds colored output noise, as well as a function that estimates three different models and plots their frequency responses. We will consider three estimation methods","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"arx, a prediction-error approach based on a least-squares estimate.\nA subspace-based method subspaceid, known to be biased in the presence of output feedback.\nThe prediction-error method (PEM) newpem","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"The ARX and PEM methods are theoretically unbiased in the presence of output feedback, see [Ljung], while the subspace-based method is not. (Note: the subspace-based method is used to form the initial guess for the iterative PEM algorithm)","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"using ControlSystemsBase, ControlSystemIdentification, Plots\ngr(fmt=:png) # hide\nG = tf(1, [1, -0.9], 1) # True system\n\nfunction generate_data(u; T)\n    E = c2d(tf(1 / 100, [1, 0.01, 0.1]), 1) # Noise model for colored noise \n    e = lsim(E, randn(1, T)).y              # Noise realization\n    function u_noise(x, t)\n        y = x .+ e[t] # Add the measured noise to the state to simulate feedback of measurement noise\n        u(y, t)\n    end\n    res = lsim(G, u_noise, 1:T, x0 = [1])\n    d = iddata(res)\n    d.y .+= e # Add the measurement noise to the output that is stored in the data object\n    d\nend\n\nfunction estimate_and_plot(d, nx=1; title, focus=:prediciton)\n    Gh1 = arx(d, 1, 1)\n\n    sys0 = subspaceid(d, nx; focus)\n    tf(sys0)\n\n    Gh2, _ = ControlSystemIdentification.newpem(d, nx; sys0, focus)\n    tf(Gh2)\n\n    figb = bodeplot(\n        [G, Gh1, sys0.sys, Gh2.sys];\n        ticks = :default,\n        title,\n        lab = [\"True system\" \"ARX\" \"Subspace\" \"PEM\"],\n        plotphase = false,\n    )\n\n    figd = plot(d)\n    plot(figb, figd)\nend","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"In the first experiment, we have no reference excitation, with a small amount of data (T=80), we get terrible estimates","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"L = 0.5 # Feedback gain u = -L*x\nu = (x, t) -> -L * x\ntitle = \"-Lx\"\nestimate_and_plot(generate_data(u, T=80), title=title*\",  T=80\")","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"with a larger amount of data T=8000, we get equally terrible estimates","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"estimate_and_plot(generate_data(u, T=8000), title=title*\",  T=8000\")","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"This indicates that we can not hope to estimate a model if the system is driven by noise only.","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"We now consider a simple, periodic excitation r = sin(t)","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"L = 0.5 # Feedback gain u = -L*x\nu = (x, t) -> -L * x .+ 5sin(t)\ntitle = \"-Lx + 5sin(t)\"\nestimate_and_plot(generate_data(u, T=80), title=title*\",  T=80\")","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"In this case, all but the subspace-based method performs quite well","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"estimate_and_plot(generate_data(u, T=8000), title=title*\",  T=8000\")","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"More data does not help the subspace method.","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"With a more complex excitation (random white-spectrum noise), all methods perform well","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"L = 0.5 # Feedback gain u = -L*x\nu = (x, t) -> -L * x .+ 5randn()\ntitle = \"-Lx + 5randn()\"\nestimate_and_plot(generate_data(u, T=80), title=title*\",  T=80\")","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"and even slightly better with more data.","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"estimate_and_plot(generate_data(u, T=8000), title=title*\",  T=8000\")","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"If the feedback is strong but the excitation is weak, the results are rather poor for all methods, it's thus important to have enough energy in the excitation compared to the feedback path.","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"L = 1 # Feedback gain u = -L*x\nu = (x, t) -> -L * x .+ 0.1randn()\ntitle = \"-Lx + 0.1randn()\"\nestimate_and_plot(generate_data(u, T=80), title=title*\",  T=80\")","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"In this case, we can try to increase the model order of the PEM and subspace-based methods to see if they are able to learn the noise model (which has two poles)","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"estimate_and_plot(generate_data(u, T=8000), 3, title=title*\",  T=8000\")","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"learning the noise model can sometimes work reasonably well, but requires more data. You may extract the learned noise model using noise_model.","category":"page"},{"location":"examples/closed_loop_id/#Detecting-the-presence-of-feedback","page":"Identification in closed loop","title":"Detecting the presence of feedback","text":"","category":"section"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"It is sometimes possible to detect the presence of feedback in a dataset by looking at the cross-correlation between input and output. For a causal system, there shouldn't be any correlation for negative lags, but feedback literally feeds outputs back to the input, leading to a reverse causality:","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"L = 0.5 # Feedback gain u = -L*x\nu = (x, t) -> -L * x .+ randn.()\ntitle = \"-Lx + 5sin(t)\"\ncrosscorplot(generate_data(u, T=500), -5:10, m=:circle)","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"Here, the plot clearly has significant correlation for both positive and negative lag, indicating the presence of feedback. The controller used here is a static P-controller, leading to a one-step correlation backwards in time. With a dynamic contorller (like a PI controller), the effect would be more significant.","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"If we remove the feedback, we get","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"L = 0.0 # no feedback\nu = (x, t) -> -L * x .+ randn.()\ntitle = \"-Lx + 5sin(t)\"\ncrosscorplot(generate_data(u, T=500), -5:10, m=:circle)","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"now, the correlation for negative lags and zero lag is mostly non-significant (below the dashed lines).","category":"page"},{"location":"examples/closed_loop_id/","page":"Identification in closed loop","title":"Identification in closed loop","text":"[Ljung]: Ljung, Lennart. \"System identification–-Theory for the user\", Ch 13.","category":"page"},{"location":"tf/#Transfer-function-estimation","page":"Transfer-function estimation","title":"Transfer function estimation","text":"","category":"section"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"This page documents how to estimate transfer functions, sometimes called ARX or ARMAX models, i.e. models on any of the forms","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"beginaligned\nG(z) = dfracB(z)A(z) = dfracb_m z^m + dots + b_0z^n + a_n-1 z^n-1 + dots + a_0 \nAy = Bu + w \nAy = Bu + Cw \nAy = Bu + 1D w\nendaligned","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"This package estimates models in discrete time, but they may be converted to continuous-time models using the function d2c from ControlSystemsBase.jl.","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"The methods available are:","category":"page"},{"location":"tf/#Functions","page":"Transfer-function estimation","title":"Functions","text":"","category":"section"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"arx: Transfer-function estimation using least-squares fitting with a closed-form solution. Supports multiple datasets and custom estimator functions.\narma: Estimate an ARMA model (no control input).\nar: Estimate an AR model (no input).\narma_ssa Estimate an ARMA model with estimated noise as input (no control input).\nplr: Transfer-function estimation (ARMAX model) using pseudo-linear regression. armax is an alias for this function. This method estimates a noise model as well.\narxar: Transfer-function estimation using generalized least-squares method. This method estimates a noise model as well.\ngetARXregressor/getARregressor: For low-level control over the estimation","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"See docstrings for further help.","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"note: Note\nMost methods for estimation of transfer functions handle SISO, SIMO or MISO systems only. For estimation of MIMO systems, consider using state-space based methods and convert the result to a transfer function using tf after estimation if required. ","category":"page"},{"location":"tf/#Usage-example:","page":"Transfer-function estimation","title":"Usage example:","text":"","category":"section"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"N  = 2000     # Number of time steps\nt  = 1:N\nΔt = 1        # Sample time\nu  = randn(N) # A random control input\nG  = tf(0.8, [1,-0.9], 1)\ny  = lsim(G,u,t)[1][:]\nyn = y\nd  = iddata(y,u,Δt)\n\nna,nb = 1,1   # Number of polynomial coefficients\n\nGls = arx(d,na,nb,stochastic=false) # set stochastic to true to get a transfer function of MonteCarloMeasurements.Particles\n@show Gls\n# TransferFunction{ControlSystemsBase.SisoRational{Float64}}\n#     0.8000000000000005\n# --------------------------\n# 1.0*z - 0.8999999999999997","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"As we can see, the model is perfectly recovered. In reality, the measurement signal is often affected by noise, in which case the estimation will suffer. To combat this, a few different options exist:","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"e  = randn(N)\nyn = y + e    # Measurement signal with noise\nd  = iddata(yn,u,Δt)\n\nna,nb,nc = 1,1,1\n\nGls      = arx(d,na,nb, stochastic=true)     # Regular least-squares estimation\nGtls     = arx(d,na,nb, estimator=tls)       # Total least-squares estimation\nGwtls    = arx(d,na,nb, estimator=wtls_estimator(y,na,nb)) # Weighted Total least-squares estimation\nGplr, Gn = plr(d,na,nb,nc, initial_order=20) # Pseudo-linear regression\n@show Gls; @show  Gtls; @show  Gwtls; @show  Gplr; @show  Gn;\n# TransferFunction{ControlSystemsBase.SisoRational{MonteCarloMeasurements.Particles{Float64,500}}}\n#     0.824 ± 0.029\n# ---------------------\n# 1.0*z - 0.713 ± 0.013\n\n# Gtls = TransferFunction{ControlSystemsBase.SisoRational{Float64}}\n#     1.848908051191616\n# -------------------------\n# 1.0*z - 0.774385918070221\n\n# Gwtls = TransferFunction{ControlSystemsBase.SisoRational{Float64}}\n#    0.8180228878106678\n# -------------------------\n# 1.0*z - 0.891939152690534\n\n# Gplr = TransferFunction{ControlSystemsBase.SisoRational{Float64}}\n#     0.8221837077656046\n# --------------------------\n# 1.0*z - 0.8896345125395438\n\n# Gn = TransferFunction{ControlSystemsBase.SisoRational{Float64}}\n#     0.9347035105826179\n# --------------------------\n# 1.0*z - 0.8896345125395438","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"We now see that the estimate using standard least-squares is heavily biased and it is wrongly certain about the estimate (notice the ± in the transfer function coefficients). Regular Total least-squares does not work well in this example, since not all variables in the regressor contain equally much noise. Weighted total least-squares does a reasonable job at recovering the true model. Pseudo-linear regression also fares okay, while simultaneously estimating a noise model. The helper function wtls_estimator(y,na,nb) returns a function that performs wtls using appropriately sized covariance matrices, based on the length of y and the model orders. Weighted total least-squares estimation is provided by TotalLeastSquares.jl. See the example notebooks for more details.","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"Uncertain transfer function with Particles coefficients can be used like any other model. Try, e.g., nyquistplot(Gls) to get a Nyquist plot with confidence bounds.","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"See also function arma for estimation of signal models without inputs.","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"A video using the function arx is available here:","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/HSx28O956kA\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"tf/#Time-series-modeling","page":"Transfer-function estimation","title":"Time-series modeling","text":"","category":"section"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"Time-series modeling can be seen as special cases of transfer-function modeling where there are no control inputs. This package is primarily focused on control system identification, but we nevertheless provide two methods aimed at time-series estimation:","category":"page"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"ar: Estimate an AR model (no input).\narma_ssa Estimate an ARMA model with estimated noise as input (no control input).","category":"page"},{"location":"tf/#Code-generation","page":"Transfer-function estimation","title":"Code generation","text":"","category":"section"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"To generate C-code for, e.g., simulating a system or filtering through an estimated transfer function, see SymbolicControlSystems.jl.","category":"page"},{"location":"tf/#Transfer-function-API","page":"Transfer-function estimation","title":"Transfer-function API","text":"","category":"section"},{"location":"tf/","page":"Transfer-function estimation","title":"Transfer-function estimation","text":"ControlSystemIdentification.arx\nControlSystemIdentification.ar\nControlSystemIdentification.arma\nControlSystemIdentification.plr\nControlSystemIdentification.arxar\nControlSystemIdentification.getARXregressor\nControlSystemIdentification.getARregressor","category":"page"},{"location":"tf/#ControlSystemIdentification.arx","page":"Transfer-function estimation","title":"ControlSystemIdentification.arx","text":"Gtf = arx(d::AbstractIdData, na, nb; inputdelay = ones(Int, size(nb)), λ = 0, estimator=\\, stochastic=false)\n\nFit a transfer Function to data using an ARX model and equation error minimization.\n\nnb and na are the number of coefficients of the numerator and denominator polynomials.\n\nInput delay can be added via inputdelay = d, which corresponds to an additional delay of z^-d. An inputdelay = 0 results in a direct term. The highest order of the B polynomial is given by nb + inputdelay - 1.  λ > 0 can be provided for L₂ regularization. estimator defaults to \\ (least squares), alternatives are estimator = tls for total least-squares estimation.  arx(Δt,yn,u,na,nb, estimator=wtls_estimator(y,na,nb) is potentially more robust in the presence of heavy measurement noise. The number of free parameters is na+nb \n\nstochastic: if true, returns a transfer function with uncertain parameters represented by MonteCarloMeasurements.Particles.\n\nSupports MISO estimation by supplying an iddata with a matrix u, with nb = [nb₁, nb₂...] and optional inputdelay = [d₁, d₂...]\n\nThis function supports multiple datasets, provided as a vector of iddata objects.\n\n\n\n\n\n","category":"function"},{"location":"tf/#ControlSystemIdentification.ar","page":"Transfer-function estimation","title":"ControlSystemIdentification.ar","text":"ar(d::AbstractIdData, na; λ=0, estimator=\\, scaleB=false, stochastic=false)\n\nEstimate an AR transfer function G = 1/A, the AR process is defined as A(z⁻¹)y(t) = e(t)\n\nArguments:\n\nd: IdData, see iddata\nna: order of the model\nλ: λ > 0 can be provided for L₂ regularization\nestimator: e.g. \\,tls,irls,rtls\nscaleB: Whether or not to scale the numerator using the variance of the prediction error.\nstochastic: if true, returns a transfer function with uncertain parameters represented by MonteCarloMeasurements.Particles.\n\nEstimation of AR models using least-squares is known to struggle with heavy measurement noise, using estimator = tls can improve the result in this case.\n\nExample\n\njulia> N = 10000\n10000\n\njulia> e = [-0.2; zeros(N-1)] # noise e\n10000-element Vector{Float64}:\n[...]\n\njulia> G = tf([1, 0], [1, -0.9], 1) # AR transfer function\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n   1.0z\n----------\n1.0z - 0.9\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> y = lsim(G, e, 1:N)[1][:] # Get output of AR transfer function from input noise e\n10000-element Vector{Float64}:\n[...]\n\njulia> Gest = ar(iddata(y), 1) # Estimate AR transfer function from output y\nTransferFunction{Discrete{Float64}, ControlSystemsBase.SisoRational{Float64}}\n          1.0z\n-------------------------\n1.0z - 0.8999999999999998\n\nSample Time: 1.0 (seconds)\nDiscrete-time transfer function model\n\njulia> G ≈ Gest # Test if estimation was correct\ntrue\n\njulia> eest = lsim(1/Gest, y, 1:N)[1][:] # recover the input noise e from output y and estimated transfer function Gest\n10000-element Vector{Float64}:\n[...]\n\njulia> isapprox(eest, e, atol = eps()) # input noise correct recovered\ntrue \n\n\n\n\n\n","category":"function"},{"location":"tf/#ControlSystemIdentification.arma","page":"Transfer-function estimation","title":"ControlSystemIdentification.arma","text":"model = arma(d::AbstractIdData, na, nc; initial_order=20, method=:ls)\n\nEstimate a Autoregressive Moving Average model with na coefficients in the denominator and nc coefficients in the numerator. Returns the model and the estimated noise sequence driving the system.\n\nArguments:\n\nd: iddata\ninitial_order: An initial AR model of this order is used to estimate the residuals\nestimator: A function (A,y)->minimizeₓ(Ax-y) default is \\ but another option is wtls_estimator(1:length(y)-initial_order,na,nc,ones(nc))\n\nSee also estimate_residuals\n\n\n\n\n\n","category":"function"},{"location":"tf/#ControlSystemIdentification.plr","page":"Transfer-function estimation","title":"ControlSystemIdentification.plr","text":"G, Gn = plr(d::AbstractIdData,na,nb,nc; initial_order = 20)\n\nPerform pseudo-linear regression to estimate a model on the form Ay = Bu + Cw The residual sequence is estimated by first estimating a high-order arx model, whereafter the estimated residual sequence is included in a second estimation problem. The return values are the estimated system model, and the estimated noise model. G and Gn will always have the same denominator polynomial.\n\narmax is an alias for plr. See also pem, ar, arx\n\n\n\n\n\n","category":"function"},{"location":"tf/#ControlSystemIdentification.arxar","page":"Transfer-function estimation","title":"ControlSystemIdentification.arxar","text":"G, H, e = arxar(d::InputOutputData, na::Int, nb::Union{Int, Vector{Int}}, nd::Int)\n\nEstimate the ARXAR model Ay = Bu + v, where v = He and H = 1/D, using generalized least-squares method. For more information see Söderström - Convergence properties of the generalized least squares identification method, 1974. \n\nArguments:\n\nd: iddata\nna: order of A\nnb: number of coefficients in B, the order is determined by nb + inputdelay - 1. In MISO estimation it takes the form nb = [nb₁, nb₂...]. \nnd: order of D\n\nKeyword Arguments:\n\nH = nothing: prior knowledge about the AR noise model\ninputdelay = ones(Int, size(nb)): optional delay of input, inputdelay = 0 results in a direct term, takes the form inputdelay = [d₁, d₂...] in MISO estimation \nλ = 0: λ > 0 can be provided for L₂ regularization\nestimator = \\: e.g. \\,tls,irls,rtls, the latter three require using TotalLeastSquares\nδmin = 10e-4: Minimal change in the power of e, that specifies convergence.\niterations = 10: maximum number of iterations.\nverbose = false: if true, more information is printed\n\nExample:\n\njulia> N = 500 \n500\n\njulia> sim(G, u) = lsim(G, u, 1:N)[1][:]\nsim (generic function with 1 method)\n\njulia> A = tf([1, -0.8], [1, 0], 1)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n1.0z - 0.8\n----------\n   1.0z\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> B = tf([0, 1], [1, 0], 1)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Int64}}\n1\n-\nz\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> G = minreal(B / A)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n   1.0\n----------\n1.0z - 0.8\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> D = tf([1, 0.7], [1, 0], 1)\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n1.0z + 0.7\n----------\n   1.0z\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> H = 1 / D\nTransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n   1.0z\n----------\n1.0z + 0.7\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model\n\njulia> u, e = randn(1, N), randn(1, N)\n[...]\n\njulia> y, v = sim(G, u), sim(H * (1/A), e) # simulate process\n[...]\n\njulia> d = iddata(y .+ v, u, 1)\nInputOutput data of length 500 with 1 outputs and 1 inputs\n\njulia> na, nb , nd = 1, 1, 1\n(1, 1, 1)\n\njulia> Gest, Hest, res = arxar(d, na, nb, nd)\n(G = TransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n   0.9987917259291642\n-------------------------\n1.0z - 0.7937837464682017\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model, H = TransferFunction{Discrete{Int64}, ControlSystemsBase.SisoRational{Float64}}\n          1.0z\n-------------------------\n1.0z + 0.7019519225937721\n\nSample Time: 1 (seconds)\nDiscrete-time transfer function model, e = [...]\n\n\n\n\n\n","category":"function"},{"location":"tf/#ControlSystemIdentification.getARXregressor","page":"Transfer-function estimation","title":"ControlSystemIdentification.getARXregressor","text":"getARXregressor(y::AbstractVector,u::AbstractVecOrMat, na, nb; inputdelay = ones(Int, size(nb)))\n\nReturns a shortened output signal y and a regressor matrix A such that the least-squares ARX model estimate of order na,nb is y\\A\n\nReturn a regressor matrix used to fit an ARX model on, e.g., the form A(z)y = B(z)u with output y and input u where the order of autoregression is na, the order of input moving average is nb and an optional input delay inputdelay. Caution, changing the input delay changes the order to nb + inputdelay - 1. An inputdelay = 0 results in a direct term. \n\nExample\n\nA     = [1,2*0.7*1,1] # A(z) coeffs\nB     = [10,5] # B(z) coeffs\nu     = randn(100) # Simulate 100 time steps with Gaussian input\ny     = filt(B,A,u)\nyr,A  = getARXregressor(y,u,3,2) # We assume that we know the system order 3,2\nx     = A\\yr # Estimate model polynomials\nplot([yr A*x], lab=[\"Signal\" \"Prediction\"])\n\nFor nonlinear ARX-models, see BasisFunctionExpansions.jl. See also arx\n\n\n\n\n\n","category":"function"},{"location":"tf/#ControlSystemIdentification.getARregressor","page":"Transfer-function estimation","title":"ControlSystemIdentification.getARregressor","text":"yt,A = getARregressor(y::AbstractVector, na)\n\nReturns values such that x = A\\yt. See getARXregressor for more details.\n\n\n\n\n\n","category":"function"},{"location":"validation/#Validation","page":"Validation","title":"Validation","text":"","category":"section"},{"location":"validation/","page":"Validation","title":"Validation","text":"A number of functions are made available to assist in validation of the estimated models. We illustrate by an example","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"Generate some test data:","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"using ControlSystemIdentification, ControlSystemsBase, Random\nusing ControlSystemIdentification: newpem\nRandom.seed!(1)\nT          = 200\nnx         = 2\nnu         = 1\nny         = 1\nx0         = randn(nx)\nσy         = 0.5\nsim(sys,u) = lsim(sys, u, 1:T)[1]\nsys        = tf(1, [1, 2*0.1, 0.1])\nsysn       = tf(σy, [1, 2*0.1, 0.3])\n# Training data\nu          = randn(nu,T)\ny          = sim(sys, u)\nyn         = y + sim(sysn, randn(size(u)))\ndn         = iddata(yn, u, 1)\n# Validation data\nuv         = randn(nu, T)\nyv         = sim(sys, uv)\nynv        = yv + sim(sysn, randn(size(uv)))\ndv         = iddata(yv, uv, 1)\ndnv        = iddata(ynv, uv, 1)","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"We then fit a couple of models","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"res = [newpem(dn, nx, focus=:prediction) for nx = [2,3,4]];\nnothing # hide","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"After fitting the models, we validate the results using the validation data and the functions simplot and predplot (cf. Matlab sys.id's compare):","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"using Plots\ngr(fmt=:png) # hide\nω   = exp10.(range(-2, stop=log10(pi), length=150))\nfig = plot(layout=4, size=(1000,600))\nfor i in eachindex(res)\n    sysh, x0h, opt = res[i]\n    simplot!( sysh, dnv, x0h; sp=1, ploty=false)\n    predplot!(sysh, dnv, x0h; sp=2, ploty=false)\nend\nplot!(dnv.y' .* [1 1], lab=\"y\", l=(:dash, :black), sp=[1 2])\nbodeplot!((getindex.(res,1)),                     ω, link = :none, balance=false, plotphase=false, subplot=3, title=\"Process\", linewidth=2*[4 3 2 1])\nbodeplot!(innovation_form.(getindex.(res,1)),     ω, link = :none, balance=false, plotphase=false, subplot=4, linewidth=2*[4 3 2 1])\nbodeplot!(sys,                                    ω, link = :none, balance=false, plotphase=false, subplot=3, lab=\"True\", l=(:black, :dash), legend = :bottomleft, title=\"System model\")\nbodeplot!(innovation_form(ss(sys),syse=ss(sysn)), ω, link = :none, balance=false, plotphase=false, subplot=4, lab=\"True\", l=(:black, :dash), ylims=(0.1, 100), legend = :bottomleft, title=\"Noise model\")","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"In the figure, simulation output is compared to the true model on the top left and prediction on top right. The system models and noise models are visualized in the bottom plots. All models capture the system dynamics reasonably well, but struggle slightly with capturing the gain of the noise dynamics. The true system has 4 poles (two in the process and two in the noise process) but a simpler model may sometimes work better.","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"Prediction models may also be evaluated using a h-step prediction, here h is short for \"horizon\".","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"figh = plot()\nfor i in eachindex(res)\n    sysh, x0h, opt = res[i]\n    predplot!(sysh, dnv, x0h, ploty=false, h=5)\nend\nplot!(dnv.y', lab=\"y\", l=(:dash, :black))\nfigh","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"It's generally a good idea to validate estimated model with a prediction horizon larger than one, in particular, it may be valuable to verify the performance for a prediction horizon that corresponds roughly to the dominant time constant of the process.","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"See also simulate, predplot, simplot, coherenceplot","category":"page"},{"location":"validation/#Different-length-predictors","page":"Validation","title":"Different length predictors","text":"","category":"section"},{"location":"validation/","page":"Validation","title":"Validation","text":"When the prediction horizon gets longer, the mapping from u rightarrow y approaches that of the simulation system, while the mapping y rightarrow y gets smaller and smaller.","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"using LinearAlgebra\nG   = c2d(DemoSystems.resonant(), 0.1)\nK   = kalman(G, I(G.nx), I(G.ny))\nsys = add_input(G, K, I(G.ny)) # Form an innovation model with inputs u and e\n\nT = 10000\nu = randn(G.nu, T)\ne = 0.1randn(G.ny, T)\ny = lsim(sys, [u; e]).y\nd = iddata(y, u, G.Ts)\nGh,_ = newpem(d, G.nx, zeroD=true)\n\n# Create predictors with different horizons\np1   = observer_predictor(Gh)\np2   = observer_predictor(Gh, h=2)\np10  = observer_predictor(Gh, h=10)\np100 = observer_predictor(Gh, h=100)\n\nbodeplot([p1, p2, p10, p100], plotphase=false, lab=[\"1\" \"\" \"2\" \"\" \"10\" \"\" \"100\" \"\"])\nbodeplot!(sys, ticks=:default, plotphase=false, l=(:black, :dash), lab=[\"sim\" \"\"], title=[\"From u\" \"From y\"])","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"The prediction error as a function of prediction horizon approaches the simulation error.","category":"page"},{"location":"validation/","page":"Validation","title":"Validation","text":"using Statistics\nhs = [1:40; 45:5:80]\nperrs = map(hs) do h\n    yh = predict(Gh, d; h)\n    ControlSystemIdentification.rms(d.y - yh) |> mean\nend\nserr = ControlSystemIdentification.rms(d.y - simulate(Gh, d)) |> mean\n\nplot(hs, perrs, lab=\"Prediction errors\", xlabel=\"Horizon\", ylabel=\"RMS error\")\nhline!([serr], lab=\"Simulation error\", l=:dash, legend=:bottomright, ylims=(0, Inf))","category":"page"},{"location":"validation/#Validation-API","page":"Validation","title":"Validation API","text":"","category":"section"},{"location":"validation/","page":"Validation","title":"Validation","text":"ControlSystemIdentification.predict\nControlSystemIdentification.simulate","category":"page"},{"location":"validation/#StatsAPI.predict","page":"Validation","title":"StatsAPI.predict","text":"predict(ARX::TransferFunction, d::InputOutputData)\n\nOne step ahead prediction for an ARX process.  The length of the returned prediction is length(d) - max(na, nb)\n\nExample:\n\njulia> predict(tf(1, [1, -1], 1), iddata(1:10, 1:10))\n9-element Vector{Int64}:\n  2\n  4\n  6\n  8\n 10\n 12\n 14\n 16\n 18\n\n\n\n\n\npredict(sys, d::AbstractIdData, args...)\npredict(sys, y, u, x0 = nothing)\n\nSee also predplot\n\n\n\n\n\nyh = predict(ar::TransferFunction, y)\n\nPredict AR model\n\n\n\n\n\n","category":"function"},{"location":"validation/#LowLevelParticleFilters.simulate","page":"Validation","title":"LowLevelParticleFilters.simulate","text":"simulate(sys, u, x0 = nothing)\nsimulate(sys, d, x0 = nothing)\n\nSee also simplot, predict\n\n\n\n\n\n","category":"function"},{"location":"validation/","page":"Validation","title":"Validation","text":"predplot\nsimplot\ncoherenceplot\nautocorplot\ncrosscorplot\nmodelfit","category":"page"},{"location":"","page":"Home","title":"Home","text":"<p style=\"text-align:center\">\n\n<img src=\"https://avatars.githubusercontent.com/u/10605979?s=400&u=7b2efdd404c4db3b3f067f04c305d40c025a8961&v=4\" alt=\"JuliaControl logo\">\n\n<br> \n\n<a class=\"github-button\" href=\"https://github.com/baggepinnen/ControlSystemIdentification.jl\" data-color-scheme=\"no-preference: light; light: light; dark: dark;\" data-icon=\"octicon-star\" data-show-count=\"true\" aria-label=\"Star baggepinnen/ControlSystemIdentification.jl on GitHub\">Star</a>\n\n<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n</p> ","category":"page"},{"location":"#ControlSystemIdentification","page":"Home","title":"ControlSystemIdentification","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: CI) (Image: codecov)","category":"page"},{"location":"","page":"Home","title":"Home","text":"System identification for ControlSystems.jl. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"System identification is the process of estimating a dynamical model from data. This packages estimates primarily linear time-invariant (LTI) models, in the form of statespace systems","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\nx^+ = Ax + Bu + Ke\ny = Cx + Du + e\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"or in the form of transfer functions","category":"page"},{"location":"","page":"Home","title":"Home","text":"Y(z) = dfracB(z)A(z)U(z)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We also have capabilities for estimation of nonlinear Hammerstein-Wiener models and linear/nonlinear gray-box identification of models in continuous or discrete time.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package is implemented in the free and open-source programming language Julia.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you are new to this package, start your journey through the documentation by learning about Identification data. Examples are provided in the Examples section and in the form of jupyter notebooks here. An introductory video is available below (system identification example starts around 55 minutes)","category":"page"},{"location":"","page":"Home","title":"Home","text":"<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Fdz2Fsm1aTY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Install Julia from the download page. Then, in the Julia REPL, type","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"ControlSystemIdentification\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Optional: To work with linear systems and plot Bode plots etc., also install the control toolbox ControlSystems.jl package which this package builds upon, as well as the plotting package","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pkg.add([\"ControlSystemIdentification\", \"ControlSystemsBase\", \"Plots\"])","category":"page"},{"location":"#Algorithm-overview","page":"Home","title":"Algorithm overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The following table indicates which estimation algorithms are applicable in different scenarios. A green circle (🟢) indicates that a particular method is well suited for the situation, an orange diamond (🔶) indicates that a match is possible, but somehow not ideal, while a red square (🟥) indicates that a method in its standard form is ill suited for the situation. The table is not exhaustive, and is intended to give a rough overview of the applicability of different algorithms.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using PrettyTables, Markdown\n\nheader = [\"Estimation method\", \"SIMO\", \"MISO\", \"Disturbance models\", \"Nonlinearities\", \"Custom loss\", \"Time domain\", \"Frequency domain\", \"Multiple dataset\"]\n\ndata = [\n    \"newpem\"            \"🟢\" \"🟢\" \"🟢\" \"🟢\" \"🟢\" \"🟢\" \"🟥\" \"🟥\"\n    \"subspaceid\"        \"🟢\" \"🟢\" \"🟢\" \"🟥\" \"🟢\" \"🟢\" \"🟢\" \"🟥\"\n    \"arx\"               \"🟥\" \"🟢\" \"🟥\" \"🔶\" \"🟢\" \"🟢\" \"🟥\" \"🟢\"\n    \"arxar\"             \"🟥\" \"🟢\" \"🟢\" \"🟥\" \"🟢\" \"🟢\" \"🟥\" \"🟥\"\n    \"plr\"               \"🟥\" \"🟢\" \"🟢\" \"🟥\" \"🟢\" \"🟢\" \"🟥\" \"🔶\"\n    \"era/okid\"          \"🟢\" \"🟢\" \"🟥\" \"🟥\" \"🟥\" \"🟢\" \"🟥\" \"🟢\"\n    \"impulseest\"        \"🟥\" \"🟢\" \"🟥\" \"🟥\" \"🟢\" \"🟢\" \"🟥\" \"🟥\"\n    \"tfest\"             \"🟥\" \"🟥\" \"🟢\" \"🟥\" \"🟢\" \"🟢\" \"🟢\" \"🟥\"\n]\n\nio = IOBuffer()\ntab = pretty_table(io, data; header, tf=tf_html_default)\ntab_algos = String(take!(io)) |> HTML","category":"page"},{"location":"","page":"Home","title":"Home","text":"tab_algos # hide","category":"page"},{"location":"#Comments","page":"Home","title":"Comments","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All methods can estimate SISO systems, i.e., systems with a single input and a single output.\nMissing from the comparison is whether an algorithm estimates a transfer function or a statespace system, this is because one can without loss convert one to the other by simply calling tf/ss. One notable exception is for non-causal transfer functions which cannot be represented as statespace systems, but those do not appear very often.\nSeveral methods are listed as 🟥 on nonlinearities, but it is oftentimes possible to handle known input nonlinearities by adding nonlinearly transformed versions of the input to the dataset. Known output nonlinearities that are invertible can be handled by similarly applying the inverse nonlinearity to the data before estimation. Only newpem has explicit methods for estimating parameters of nonlinearities. arx is listed as 🔶, since with the correct estimator option that promotes sparsity, it is possible to find the most appropriate nonlinearity among a set of candidates. However, no explicit support for this is provided.\nCustom loss functions are sometimes supported explicitly, such as for newpem, but often supported by providing a custom estimator for methods that solve a problem on the form operatornameargmin_w sum_i operatornameloss(e_i) quad forall e_i in e = y - Aw. The default estimator in these cases is always \\, i.e., to solve a least-squares problem. Useful alternatives are, e.g., TotalLeastSquares.tls and TotalLeastSquares.irls. This can be useful to increase robustness w.r.t. noise etc.\nIn specific situations it is possible to use any method with multiple datasets by simply concatenating two datasets like [d1 d2]. This is only recommended if the state of the system in the end of the first dataset is very close to the state of the system in the beginning of the second dataset, for example, if all experiments start and end at rest in the origin.\nSome methods estimate explicit disturbance models, such as plr and arxar, whereas other methods estimate observers with an implicit disturbance model, such as newpem and subspaceid. All methods that estimate disturbance models are able to account for input disturbance (also referred to as dynamic disturbance or load disturbance).","category":"page"},{"location":"#Other-resources","page":"Home","title":"Other resources","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For estimation of linear time-varying models (LTV), see LTVModels.jl.\nFor estimation of linear and nonlinear grey-box models in continuous time, see DifferentialEquations.jl (parameter estimation)\nEstimation of nonlinear black-box models in continuous time DiffEqFlux.jl and DataDrivenDiffEq.jl\nFor more advanced spectral estimation, cross coherence, etc., see LPVSpectral.jl\nThis package interacts well with MonteCarloMeasurements.jl. See example file.\nState estimation is facilitated by LowLevelParticleFilters.jl.","category":"page"},{"location":"iddata/#Identification-data","page":"Identification data","title":"Identification data","text":"","category":"section"},{"location":"iddata/","page":"Identification data","title":"Identification data","text":"All estimation methods in this package expect an object of type AbstractIdData, created using the function iddata. This object typically holds input and output data as well as the sample time. ","category":"page"},{"location":"iddata/","page":"Identification data","title":"Identification data","text":"ControlSystemIdentification.iddata\nControlSystemIdentification.predictiondata","category":"page"},{"location":"iddata/#ControlSystemIdentification.iddata","page":"Identification data","title":"ControlSystemIdentification.iddata","text":"iddata(y,       Ts = nothing)\niddata(y, u,    Ts = nothing)\niddata(y, u, x, Ts = nothing)\n\nCreate a time-domain identification data object. \n\nArguments\n\ny::AbstractArray: output data (required)\nu::AbstractArray: input data (if available)\nx::AbstractArray: state data (if available)\nTs::Union{Real,Nothing} = nothing: optional sample time\n\nIf the time-series are multivariate, time is in the last dimension, i.e., the sizes of the arrays are (num_variables, num_timepoints) (see examples below).\n\nOperations on iddata\n\ndetrend\nprefilter\nresample\nappend two along the time dimension [d1 d2] (only do this if the state of the system at the end of d1 is close to the state at the beginning of d2)\nindex time series d[output_index, input_index]\nindex the time axis with indices d[time_indices]\nindex the time axis with seconds d[3Sec:12Sec] (using ControlSystemIdentification: Sec)\naccess number of inputs, outputs and sample time: d.nu, d.ny, d.Ts\naccess the time time vector d.t\npremultiply to scale outputs C * d. Scaling the outputs of a multiple-output system to have roughly the same size is usually recommended before estimating a model in case they have different magnitudes.\npostmultiply to scale inputs d * B\nwritedlm\nramp_in, ramp_out\nplot\nspecplot\ncrosscorplot\n\nExamples\n\njulia> iddata(randn(10))\nOutput data of length 10 with 1 outputs, Ts = nothing\n\njulia> iddata(randn(10), randn(10), 1)\nInputOutput data of length 10, 1 outputs, 1 inputs, Ts = 1\n\njulia> d = iddata(randn(2, 10), randn(3, 10), 0.1)\nInputOutput data of length 10, 2 outputs, 3 inputs, Ts = 0.1\n\njulia> [d d] # Concatenate along time\nInputOutput data of length 20, 2 outputs, 3 inputs, Ts = 0.1\n\njulia> d[1:3]\nInputOutput data of length 3, 2 outputs, 3 inputs, Ts = 0.1\n\njulia> d.nu\n3\n\njulia> d.t # access time vector\n0.0:0.1:0.9\n\nUse of multiple datasets\n\nSome estimation methods support the use of multiple datasets to estimate a model. In this case, the datasets are provided as a vector of iddata objects. The methods that currently support this are:\n\narx\nera\n\nSeveral of the other estimation methods can be made to accept multiple datasets with minor modifications.\n\nIn some situations, multiple datasets can also be handled by concatination. For this to be a good idea, the state of the system at the end of one data set must be close to the state at the beginning of the next, e.g., all experiments start and end at the same operating point.\n\n\n\n\n\niddata(y::AbstractArray, u::AbstractArray, w::AbstractVector)\n\nCreate a frequency-domain input-output data object. w is expected to be in rad/s.\n\n\n\n\n\niddata(res::ControlSystemsBase.SimResult)\n\nCreate an identification-data object directly from a simulation result.\n\n\n\n\n\n","category":"function"},{"location":"iddata/#ControlSystemIdentification.predictiondata","page":"Identification data","title":"ControlSystemIdentification.predictiondata","text":"predictiondata(d::AbstractIdData)\n\nAdd the output y to the input u_new = [u; y]\n\n\n\n\n\n","category":"function"},{"location":"iddata/","page":"Identification data","title":"Identification data","text":"Some frequency-domain methods accept or return objects of type FRD, representing frequency-response data. An FRD object can be created directly using the constructor, or using the appropriate iddata method above.","category":"page"}]
}
